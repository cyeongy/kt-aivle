{"cells":[{"cell_type":"markdown","metadata":{"id":"52e1f0fb"},"source":["# 안녕하세요^^ \n","# AIVLE 미니 프로젝트에 오신 여러분을 환영합니다.\n","* 본 과정에서는 실제 사례와 데이터를 기반으로 문제를 해결하는 전체 과정을 자기 주도형 실습으로 진행해볼 예정입니다.\n","* 앞선 교육과정을 정리하는 마음과 지금까지 배운 내용을 바탕으로 문제 해결을 해볼게요!\n","* 미니 프로젝트를 통한 문제 해결 과정 'A에서 Z까지', 지금부터 시작합니다!"],"id":"52e1f0fb"},{"cell_type":"markdown","metadata":{"id":"nUXBrxPDiFd9"},"source":["---"],"id":"nUXBrxPDiFd9"},{"cell_type":"markdown","metadata":{"id":"orwgQqTkEW0C"},"source":["# __[Study] 2. 구글 오픈 이미지 데이터 셋 활용 YOLOv5 ObjectDetection__\n","- Google Open Image Data?<br>\n","구글이 머신러닝을 위해 2016년에 공개한 이미지에 주석이 달린 데이터셋으로 약 190만개에 전문 라벨러들이 라벨링을 검수한 이미지들을 포함하고 있습니다. 데이터셋은 V1부터 계속 업데이트 되어 2020년 2월 기준으로 가장 최신 버전인 V6버전까지 공개되었습니다.\n"],"id":"orwgQqTkEW0C"},{"cell_type":"markdown","metadata":{"id":"ZPJwlsgmDmMQ"},"source":["## 0. 환경 설정하기"],"id":"ZPJwlsgmDmMQ"},{"cell_type":"markdown","metadata":{"id":"Y5OZR2I9sfVq"},"source":["### 1) 구글 드라이브 연결하기\n"],"id":"Y5OZR2I9sfVq"},{"cell_type":"code","execution_count":null,"metadata":{"id":"opm0PySCseDD"},"outputs":[],"source":["# 코랩 사용 시 구글 드라이브 연결\n","from google.colab import drive\n","drive.mount('/content/drive')"],"id":"opm0PySCseDD"},{"cell_type":"markdown","metadata":{"id":"bzQ5ZM05swzJ"},"source":["### 2) 경로 확인하기\n","- \"WORK_SPACE\" 에 본인 작업 경로 작성 후 실행(구글 드라이브 최상위에 압축해제 시 그대로 실행. 수정 X).<br>"],"id":"bzQ5ZM05swzJ"},{"cell_type":"code","execution_count":null,"metadata":{"id":"I66_jbFEsuz9"},"outputs":[],"source":["# ROOT_PATH 확인 \n","import os\n","\n","# 구글 드라이브 내 프로젝트 압축해제된 영역 (구글 드라이브 최상위에 압축해제하였을 경우 수정하지 않으셔도 됩니다.)\n","WORK_SPACE = \"\"\n","\n","if os.getcwd() == '/content' :\n","  # 구글 드라이브 사용 시 \n","  ROOT_PATH = '/content' + WORK_SPACE\n","else :\n","  ROOT_PATH = os.path.abspath('..')\n","\n"],"id":"I66_jbFEsuz9"},{"cell_type":"markdown","metadata":{"id":"xB7iJVzd7eHh"},"source":["### 3) YOLOv5파일 다운로드 및 설치\n","\n","![install](https://github.com/DrKAI/CV/raw/main/UltraLytics_manual/yolov5_install.png)\n","\n","[Install Page](https://github.com/ultralytics/yolov5)\n","\n"],"id":"xB7iJVzd7eHh"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2061,"status":"ok","timestamp":1666264452711,"user":{"displayName":"석재민","userId":"11162518966479505622"},"user_tz":-540},"id":"E8ClcNk0cU7A","outputId":"4dcf9c5f-19b8-44f5-8ab7-294270a19fe8"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content\n","Cloning into 'yolov5'...\n","remote: Enumerating objects: 14298, done.\u001b[K\n","remote: Counting objects: 100% (104/104), done.\u001b[K\n","remote: Compressing objects: 100% (73/73), done.\u001b[K\n","remote: Total 14298 (delta 62), reused 65 (delta 31), pack-reused 14194\u001b[K\n","Receiving objects: 100% (14298/14298), 13.39 MiB | 13.54 MiB/s, done.\n","Resolving deltas: 100% (9877/9877), done.\n"]}],"source":["# UltraLytics git에서 복사하기\n","%cd /content\n","!git clone https://github.com/ultralytics/yolov5"],"id":"E8ClcNk0cU7A"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2809,"status":"ok","timestamp":1666264460008,"user":{"displayName":"석재민","userId":"11162518966479505622"},"user_tz":-540},"id":"_0O_N_2VctaW","outputId":"5ae4a2b0-fde4-4b20-9603-b0e455788f8c"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/yolov5\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: matplotlib>=3.2.2 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 5)) (3.2.2)\n","Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 6)) (1.21.6)\n","Requirement already satisfied: opencv-python>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 7)) (4.6.0.66)\n","Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 8)) (7.1.2)\n","Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 9)) (5.4.1)\n","Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 10)) (2.23.0)\n","Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 11)) (1.7.3)\n","Requirement already satisfied: torch>=1.7.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 12)) (1.12.1+cu113)\n","Requirement already satisfied: torchvision>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 13)) (0.13.1+cu113)\n","Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 14)) (4.64.1)\n","Requirement already satisfied: tensorboard>=2.4.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 18)) (2.9.1)\n","Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 23)) (1.3.5)\n","Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 24)) (0.11.2)\n","Requirement already satisfied: ipython in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 41)) (7.9.0)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 42)) (5.4.8)\n","Requirement already satisfied: thop>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 43)) (0.1.1.post2209072238)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 5)) (0.11.0)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 5)) (2.8.2)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 5)) (1.4.4)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 5)) (3.0.9)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.23.0->-r requirements.txt (line 10)) (2022.9.24)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.23.0->-r requirements.txt (line 10)) (1.25.11)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.23.0->-r requirements.txt (line 10)) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.23.0->-r requirements.txt (line 10)) (3.0.4)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.7.0->-r requirements.txt (line 12)) (4.1.1)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 18)) (1.8.1)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 18)) (0.4.6)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 18)) (0.6.1)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 18)) (1.35.0)\n","Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 18)) (0.37.1)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 18)) (3.4.1)\n","Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 18)) (1.3.0)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 18)) (1.0.1)\n","Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 18)) (3.17.3)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 18)) (57.4.0)\n","Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 18)) (1.49.1)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.1.4->-r requirements.txt (line 23)) (2022.4)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 18)) (4.7.2)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 18)) (4.2.4)\n","Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 18)) (1.15.0)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 18)) (0.2.8)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.4.1->-r requirements.txt (line 18)) (1.3.1)\n","Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard>=2.4.1->-r requirements.txt (line 18)) (4.13.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard>=2.4.1->-r requirements.txt (line 18)) (3.9.0)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 18)) (0.4.8)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.4.1->-r requirements.txt (line 18)) (3.2.1)\n","Requirement already satisfied: jedi>=0.10 in /usr/local/lib/python3.7/dist-packages (from ipython->-r requirements.txt (line 41)) (0.18.1)\n","Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipython->-r requirements.txt (line 41)) (5.1.1)\n","Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython->-r requirements.txt (line 41)) (4.4.2)\n","Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython->-r requirements.txt (line 41)) (4.8.0)\n","Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython->-r requirements.txt (line 41)) (2.6.1)\n","Requirement already satisfied: backcall in /usr/local/lib/python3.7/dist-packages (from ipython->-r requirements.txt (line 41)) (0.2.0)\n","Requirement already satisfied: prompt-toolkit<2.1.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from ipython->-r requirements.txt (line 41)) (2.0.10)\n","Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython->-r requirements.txt (line 41)) (0.7.5)\n","Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from jedi>=0.10->ipython->-r requirements.txt (line 41)) (0.8.3)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython->-r requirements.txt (line 41)) (0.2.5)\n","Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect->ipython->-r requirements.txt (line 41)) (0.7.0)\n"]}],"source":["# yolov5 폴더 이동 및 requirements.txt 내부 패키지 설치\n","%cd /content/yolov5\n","!pip install -r requirements.txt"],"id":"_0O_N_2VctaW"},{"cell_type":"markdown","metadata":{"id":"av7r3quaDmMV"},"source":["### 4) 라이브러리 불러오기\n","필요시 추가 라이브러리는 설치해서 사용하세요."],"id":"av7r3quaDmMV"},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZYimZcrODmMW","scrolled":false},"outputs":[],"source":["# 필요 라이브러리 불러오기.\n","import glob\n","import yaml\n","from IPython.display import Image"],"id":"ZYimZcrODmMW"},{"cell_type":"markdown","metadata":{"id":"49648b6d"},"source":["---"],"id":"49648b6d"},{"cell_type":"markdown","metadata":{"id":"vocational-animal"},"source":["## 1. 데이터 불러오기\n","* OIDv4_ToolKit을 활용하여 Google Open Dataset 다운로드하기\n","> ① Google Open Dataset 검색<br>\n","  https://storage.googleapis.com/openimages/web/index.html<br>\n","  Google Open Image Dataset 특징 : COCO와 비슷하지만, 용량은 훨씬 많음.<br>\n","> ② OID Toolkit 설치<br>\n","  https://github.com/EscVM/OIDv4_ToolKit/<br>\n","  https://github.com/theAIGuysCode/OIDv4_ToolKit/<br> \n","```# 코드로 형식 지정됨\n","!git clone https://github.com/theAIGuysCode/OIDv4_ToolKit.git\n","%cd OIDv4_ToolKit\n","!pip install -r requirements.txt\n","```\n","> ③ OID Toolkit을 활용하여 Dataset 다운로드 하기<br>\n","```# 코드로 형식 지정됨\n","!python main.py downloader --classes Apple Orange --type_csv validation\n","```\n"],"id":"vocational-animal"},{"cell_type":"markdown","metadata":{"id":"OTqROJ9xMyPk"},"source":["<font color=\"green\">[실습문제]</font> 1. OID Toolkit을 다운로드하고 설치하세요."],"id":"OTqROJ9xMyPk"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1666261827122,"user":{"displayName":"석재민","userId":"11162518966479505622"},"user_tz":-540},"id":"FgwGNwAR7KSd","outputId":"3436f83e-fb97-49cf-e356-ee5e7506d240"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content\n"]}],"source":["# 현재 경로 화인하기\n","%pwd\n","%cd /content"],"id":"FgwGNwAR7KSd"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":21878,"status":"ok","timestamp":1666261850532,"user":{"displayName":"석재민","userId":"11162518966479505622"},"user_tz":-540},"id":"W_YVEdsh2LL7","outputId":"247f6610-b4ef-4329-afb5-315526672160"},"outputs":[{"name":"stdout","output_type":"stream","text":["Cloning into 'OIDv4_ToolKit'...\n","remote: Enumerating objects: 444, done.\u001b[K\n","remote: Total 444 (delta 0), reused 0 (delta 0), pack-reused 444\u001b[K\n","Receiving objects: 100% (444/444), 34.09 MiB | 10.20 MiB/s, done.\n","Resolving deltas: 100% (157/157), done.\n","/content/OIDv4_ToolKit\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 1)) (1.3.5)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 2)) (1.21.6)\n","Collecting awscli\n","  Downloading awscli-1.25.95-py3-none-any.whl (3.9 MB)\n","\u001b[K     |████████████████████████████████| 3.9 MB 34.0 MB/s \n","\u001b[?25hRequirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 4)) (1.24.3)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 5)) (4.64.1)\n","Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 6)) (4.6.0.66)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->-r requirements.txt (line 1)) (2022.4)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->-r requirements.txt (line 1)) (2.8.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->-r requirements.txt (line 1)) (1.15.0)\n","Collecting botocore==1.27.94\n","  Downloading botocore-1.27.94-py3-none-any.whl (9.3 MB)\n","\u001b[K     |████████████████████████████████| 9.3 MB 59.2 MB/s \n","\u001b[?25hCollecting rsa<4.8,>=3.1.2\n","  Downloading rsa-4.7.2-py3-none-any.whl (34 kB)\n","Collecting docutils<0.17,>=0.10\n","  Downloading docutils-0.16-py2.py3-none-any.whl (548 kB)\n","\u001b[K     |████████████████████████████████| 548 kB 72.7 MB/s \n","\u001b[?25hCollecting PyYAML<5.5,>=3.10\n","  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n","\u001b[K     |████████████████████████████████| 636 kB 74.3 MB/s \n","\u001b[?25hCollecting s3transfer<0.7.0,>=0.6.0\n","  Downloading s3transfer-0.6.0-py3-none-any.whl (79 kB)\n","\u001b[K     |████████████████████████████████| 79 kB 3.7 MB/s \n","\u001b[?25hCollecting colorama<0.4.5,>=0.2.5\n","  Downloading colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n","Collecting jmespath<2.0.0,>=0.7.1\n","  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n","Collecting urllib3\n","  Downloading urllib3-1.26.12-py2.py3-none-any.whl (140 kB)\n","\u001b[K     |████████████████████████████████| 140 kB 72.7 MB/s \n","\u001b[?25hRequirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.7/dist-packages (from rsa<4.8,>=3.1.2->awscli->-r requirements.txt (line 3)) (0.4.8)\n","Installing collected packages: urllib3, jmespath, botocore, s3transfer, rsa, PyYAML, docutils, colorama, awscli\n","  Attempting uninstall: urllib3\n","    Found existing installation: urllib3 1.24.3\n","    Uninstalling urllib3-1.24.3:\n","      Successfully uninstalled urllib3-1.24.3\n","  Attempting uninstall: rsa\n","    Found existing installation: rsa 4.9\n","    Uninstalling rsa-4.9:\n","      Successfully uninstalled rsa-4.9\n","  Attempting uninstall: PyYAML\n","    Found existing installation: PyYAML 6.0\n","    Uninstalling PyYAML-6.0:\n","      Successfully uninstalled PyYAML-6.0\n","  Attempting uninstall: docutils\n","    Found existing installation: docutils 0.17.1\n","    Uninstalling docutils-0.17.1:\n","      Successfully uninstalled docutils-0.17.1\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","requests 2.23.0 requires urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1, but you have urllib3 1.26.12 which is incompatible.\u001b[0m\n","Successfully installed PyYAML-5.4.1 awscli-1.25.95 botocore-1.27.94 colorama-0.4.4 docutils-0.16 jmespath-1.0.1 rsa-4.7.2 s3transfer-0.6.0 urllib3-1.26.12\n"]}],"source":["# 실습해보세요\n","!git clone https://github.com/theAIGuysCode/OIDv4_ToolKit.git\n","%cd OIDv4_ToolKit\n","!pip install -r requirements.txt"],"id":"W_YVEdsh2LL7"},{"cell_type":"markdown","metadata":{"id":"tgKkaBmH1kVf"},"source":["<font color=\"green\">[실습문제]</font> 2. OID Toolkit을 활용하여 Google Open Dataset 에서 'Helmet', 'Person' 키워드로 검색한 데이터 셋을 다운로드 하세요.\n","> --classes : Helmet, Person<br>\n","> --multiclasses : 다양한 class의 이미지를 다른 폴더에 넣는게 아니라 하나의 폴더에 묶어서 다운로드<br>\n","> --limit : 카테고리당, 최대 이미지 수<br>"],"id":"tgKkaBmH1kVf"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":215174,"status":"ok","timestamp":1666262114894,"user":{"displayName":"석재민","userId":"11162518966479505622"},"user_tz":-540},"id":"BRgP4wKe1jkI","outputId":"ddf1c638-2d69-4876-c005-45ef8dd8b98b"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[92m\n","\t\t   ___   _____  ______            _    _    \n","\t\t .'   `.|_   _||_   _ `.         | |  | |   \n","\t\t/  .-.  \\ | |    | | `. \\ _   __ | |__| |_  \n","\t\t| |   | | | |    | |  | |[ \\ [  ]|____   _| \n","\t\t\\  `-'  /_| |_  _| |_.' / \\ \\/ /     _| |_  \n","\t\t `.___.'|_____||______.'   \\__/     |_____|\n","\t\u001b[0m\n","\u001b[92m\n","             _____                    _                 _             \n","            (____ \\                  | |               | |            \n","             _   \\ \\ ___  _ _ _ ____ | | ___   ____  _ | | ____  ____ \n","            | |   | / _ \\| | | |  _ \\| |/ _ \\ / _  |/ || |/ _  )/ ___)\n","            | |__/ / |_| | | | | | | | | |_| ( ( | ( (_| ( (/ /| |    \n","            |_____/ \\___/ \\____|_| |_|_|\\___/ \\_||_|\\____|\\____)_|    \n","                                                          \n","        \u001b[0m\n","    [INFO] | Downloading ['Helmet', 'Person'] together.\u001b[0m\n","\u001b[91m   [ERROR] | Missing the class-descriptions-boxable.csv file.\u001b[0m\n","\u001b[94m[DOWNLOAD] | Automatic download.\u001b[0m\n","\r...72%, 0 MB, 46665 KB/s, 0 seconds passed\r...145%, 0 MB, 33570 KB/s, 0 seconds passed\n","\u001b[94m[DOWNLOAD] | File class-descriptions-boxable.csv downloaded into OID/csv_folder/class-descriptions-boxable.csv.\u001b[0m\n","\u001b[91m   [ERROR] | Missing the train-annotations-bbox.csv file.\u001b[0m\n","\u001b[94m[DOWNLOAD] | Automatic download.\u001b[0m\n","...100%, 1138 MB, 36432 KB/s, 32 seconds passed\n","\u001b[94m[DOWNLOAD] | File train-annotations-bbox.csv downloaded into OID/csv_folder/train-annotations-bbox.csv.\u001b[0m\n","\n","\u001b[95mHelmet\u001b[0m\n","    [INFO] | Downloading train images.\u001b[0m\n","    [INFO] | [INFO] Found 7608 online images for train.\u001b[0m\n","    [INFO] | Limiting to 100 images.\u001b[0m\n","    [INFO] | Download of 100 images in train.\u001b[0m\n","100% 100/100 [00:42<00:00,  2.34it/s]\n","    [INFO] | Done!\u001b[0m\n","    [INFO] | Creating labels for Helmet of train.\u001b[0m\n","    [INFO] | Labels creation completed.\u001b[0m\n","\n","\u001b[95mPerson\u001b[0m\n","    [INFO] | Downloading train images.\u001b[0m\n","    [INFO] | [INFO] Found 248384 online images for train.\u001b[0m\n","    [INFO] | Limiting to 100 images.\u001b[0m\n","    [INFO] | Download of 99 images in train.\u001b[0m\n","100% 99/99 [00:45<00:00,  2.19it/s]\n","    [INFO] | Done!\u001b[0m\n","    [INFO] | Creating labels for Person of train.\u001b[0m\n","    [INFO] | Labels creation completed.\u001b[0m\n","\u001b[92m\n","\t\t   ___   _____  ______            _    _    \n","\t\t .'   `.|_   _||_   _ `.         | |  | |   \n","\t\t/  .-.  \\ | |    | | `. \\ _   __ | |__| |_  \n","\t\t| |   | | | |    | |  | |[ \\ [  ]|____   _| \n","\t\t\\  `-'  /_| |_  _| |_.' / \\ \\/ /     _| |_  \n","\t\t `.___.'|_____||______.'   \\__/     |_____|\n","\t\u001b[0m\n","\u001b[92m\n","             _____                    _                 _             \n","            (____ \\                  | |               | |            \n","             _   \\ \\ ___  _ _ _ ____ | | ___   ____  _ | | ____  ____ \n","            | |   | / _ \\| | | |  _ \\| |/ _ \\ / _  |/ || |/ _  )/ ___)\n","            | |__/ / |_| | | | | | | | | |_| ( ( | ( (_| ( (/ /| |    \n","            |_____/ \\___/ \\____|_| |_|_|\\___/ \\_||_|\\____|\\____)_|    \n","                                                          \n","        \u001b[0m\n","    [INFO] | Downloading ['Helmet', 'Person'] together.\u001b[0m\n","\u001b[91m   [ERROR] | Missing the validation-annotations-bbox.csv file.\u001b[0m\n","\u001b[94m[DOWNLOAD] | Automatic download.\u001b[0m\n","...100%, 16 MB, 17108 KB/s, 0 seconds passed\n","\u001b[94m[DOWNLOAD] | File validation-annotations-bbox.csv downloaded into OID/csv_folder/validation-annotations-bbox.csv.\u001b[0m\n","\n","\u001b[95mHelmet\u001b[0m\n","    [INFO] | Downloading validation images.\u001b[0m\n","    [INFO] | [INFO] Found 274 online images for validation.\u001b[0m\n","    [INFO] | Limiting to 50 images.\u001b[0m\n","    [INFO] | Download of 50 images in validation.\u001b[0m\n","100% 50/50 [00:23<00:00,  2.11it/s]\n","    [INFO] | Done!\u001b[0m\n","    [INFO] | Creating labels for Helmet of validation.\u001b[0m\n","    [INFO] | Labels creation completed.\u001b[0m\n","\n","\u001b[95mPerson\u001b[0m\n","    [INFO] | Downloading validation images.\u001b[0m\n","    [INFO] | [INFO] Found 6436 online images for validation.\u001b[0m\n","    [INFO] | Limiting to 50 images.\u001b[0m\n","    [INFO] | Download of 49 images in validation.\u001b[0m\n","100% 49/49 [00:25<00:00,  1.92it/s]\n","    [INFO] | Done!\u001b[0m\n","    [INFO] | Creating labels for Person of validation.\u001b[0m\n","    [INFO] | Labels creation completed.\u001b[0m\n"]}],"source":["!python main.py downloader --classes Helmet Person --type_csv train --multiclasses 1 --limit 100 -y\n","!python main.py downloader --classes Helmet Person --type_csv validation --multiclasses 1 --limit 50 -y"],"id":"BRgP4wKe1jkI"},{"cell_type":"markdown","metadata":{"id":"3d25c0a2"},"source":["## 2. 모델링을 위한 Train Data(학습)와 Validation 데이터(검증) 확인\n","* 다운로드 완료된 데이터는 '/content/OID/OIDv4_ToolKit/OID/Dataset/\"에 위치하고 있습니다.\n","* [Tip] 폴더 구조를 불러올 때 쓰는 glob 라이브러리 활용\n","\n","> [방법1] \n",">> DATA_PATH = \"/content/OIDv4_ToolKit/OID/Dataset\" <br>\n",">> TRAIN_PATH = \"/content/OIDv4_ToolKit/OID/Dataset/train\"<br>\n",">> VALIDATION_PATH = \"/content/OIDv4_ToolKit/OID/Dataset/validation\"<br>"],"id":"3d25c0a2"},{"cell_type":"markdown","metadata":{"id":"uKsfTWsUNUrj"},"source":["<font color=\"green\">[실습문제]</font> 3. Train Data와 Test Data 이미지 개수를 확인하세요."],"id":"uKsfTWsUNUrj"},{"cell_type":"code","execution_count":null,"metadata":{"id":"KfH7TeTQ-jC6"},"outputs":[],"source":["# 라이브러리 불러오기\n","import glob"],"id":"KfH7TeTQ-jC6"},{"cell_type":"code","execution_count":null,"metadata":{"id":"500TMbwkNoYV"},"outputs":[],"source":["# 실습해보세요.\n","train_image_list = glob.glob(\"/content/OIDv4_ToolKit/OID/Dataset/train/*/*.jpg\")\n","validation_image_list = glob.glob(\"/content/OIDv4_ToolKit/OID/Dataset/validation/*/*.jpg\")"],"id":"500TMbwkNoYV"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1,"status":"ok","timestamp":1666262805279,"user":{"displayName":"석재민","userId":"11162518966479505622"},"user_tz":-540},"id":"hCGtY3ypqROn","outputId":"c131775d-4635-48fd-ef0b-ce98bdece1ff"},"outputs":[{"name":"stdout","output_type":"stream","text":["학습 데이터(이미지) 개수 : 199\n","검증 데이터(이미지) 개수 : 99\n"]}],"source":["print(\"학습 데이터(이미지) 개수 : \" + str(len(train_image_list)))\n","print(\"검증 데이터(이미지) 개수 : \" + str(len(validation_image_list)))"],"id":"hCGtY3ypqROn"},{"cell_type":"markdown","metadata":{"id":"RU_w0oUlKwpU"},"source":["<font color=\"green\">[실습문제]</font> 4. label 디렉토리 내 .txt 파일을 확인하여 YOlOv5 학습을 위한 label .txt 파일과의 차이를 확인하세요.  <br> \n","> [Tip] 리눅스에서 파일 내용을 확인할 때는 cat 명령어를 사용합니다."],"id":"RU_w0oUlKwpU"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1666262809454,"user":{"displayName":"석재민","userId":"11162518966479505622"},"user_tz":-540},"id":"jTKotm04Kryj","outputId":"95dcc387-628a-4be7-d9c1-3983667a8e75"},"outputs":[{"name":"stdout","output_type":"stream","text":["Person 0.0 219.124158 91.52 338.937384\n","Person 65.28 107.639434 533.76 682.359346\n","Person 516.48 170.429673 867.84 681.718692\n"]}],"source":["# 실습해보세요.\n","train_label_list = glob.glob(\"/content/OIDv4_ToolKit/OID/Dataset/train//Helmet_Person/Label/*.txt\")\n","%cat \"{label_list[100]}\""],"id":"jTKotm04Kryj"},{"cell_type":"markdown","metadata":{"id":"ooJza-Gx2kaD"},"source":["<font color=\"green\">[실습문제]</font> 5. \"/OIDv4_Toolkit\" 내 \"classes.txt\" 파일의 class 구성을 Helmet, Person으로 수정하고,<br>\n","&emsp;&emsp;&emsp;&emsp;&emsp;YOLO 학습을 위해 center_x, center_t, Dw, Dh 의 값을 정규화 후 다시 생성된 label .txt 파일을 확인해보세요.<br> \n","> [Tip] 정규화는 covert_annotaion.py 모듈을 활용하시면 진행 가능합니다.<br>\n","> &emsp;&emsp; Python 모듈은 !python ooooooo.py command를 입력하면 실행 가능합니다. <br>\n","> &emsp;&emsp; 새로 생성된 label .txt 파일은 이미지가 있는 경로(\"/Helmet_Person\")에 함께 생성됩니다."],"id":"ooJza-Gx2kaD"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1,"status":"ok","timestamp":1666262536114,"user":{"displayName":"석재민","userId":"11162518966479505622"},"user_tz":-540},"id":"zvIkivou_DFP","outputId":"846d0e87-279c-48f1-f78a-f9165ed04286"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/OIDv4_ToolKit\n"]}],"source":["# 현재 경로 확인\n","%pwd\n","%cd /content/OIDv4_ToolKit/\n"],"id":"zvIkivou_DFP"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14781,"status":"ok","timestamp":1666264073242,"user":{"displayName":"석재민","userId":"11162518966479505622"},"user_tz":-540},"id":"wGVKlPB92j3a","outputId":"9d1a1795-0e32-489b-d6e1-2c29a6627334"},"outputs":[{"name":"stdout","output_type":"stream","text":["Currently in subdirectory: validation\n","Converting annotations for class:  Helmet_Person\n","100% 99/99 [00:02<00:00, 36.19it/s]\n","Currently in subdirectory: train\n","Converting annotations for class:  Helmet_Person\n","100% 199/199 [00:11<00:00, 17.21it/s]\n"]}],"source":["# 실습해보세요.\n","!python convert_annotations.py"],"id":"wGVKlPB92j3a"},{"cell_type":"code","execution_count":null,"metadata":{"id":"FBC5up3s1vMN"},"outputs":[],"source":["train_label_list = glob.glob(\"/content/OIDv4_ToolKit/OID/Dataset/train//Helmet_Person/*.txt\")\n","validation_label_list = glob.glob(\"/content/OIDv4_ToolKit/OID/Dataset/validation//Helmet_Person/*.txt\")\n","%cat \"{label_list[100]}\""],"id":"FBC5up3s1vMN"},{"cell_type":"markdown","metadata":{"id":"dDJfSRaPBtPy"},"source":["<font color=\"green\">[실습문제]</font> 6. annotraion 정보를 convert 완료된 데이터를 복사/이동하여 YOLOv5 학습을 위한 디렉토리 구조로 변경합니다.<br>\n","* YOLOv5 모델링을 위해서 데이터 디렉터리 구조는 다음과 같이 만들어야 합니다.<br>\n","- 데이터 디렉터리 구조 <br>\n","> data ─ train&ensp;┐ <br>\n","> &emsp;&emsp;&emsp;&emsp;&emsp;&emsp;├ images <br>\n","> &emsp;&emsp;&emsp;&emsp;&emsp;&emsp;├ labels <br>\n","> &emsp;&emsp; ─ validation&ensp; ┐ <br>\n","> &emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&ensp;├ images <br>\n","> &emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&ensp;├ labels <br>"],"id":"dDJfSRaPBtPy"},{"cell_type":"code","execution_count":null,"metadata":{"id":"hpFtBcC-BnRI"},"outputs":[],"source":["# DATA_PATH 지정하기\n","DATA_PATH = \"/content/data\"\n","TRAIN_PATH = DATA_PATH + \"/train\"\n","VALIDATION_PATH = DATA_PATH + \"/validation\"\n","\n","import shutil\n","\n","def file_copy(file_list, file_path):\n","  if not os.path.exists(file_path):\n","    os.makedirs(file_path)  \n","  for f in file_list:\n","    shutil.move(f, file_path)\n"],"id":"hpFtBcC-BnRI"},{"cell_type":"code","execution_count":null,"metadata":{"id":"saORJr0OBY-l"},"outputs":[],"source":["file_copy(train_label_list, TRAIN_PATH + \"/labels\")\n","file_copy(train_image_list, TRAIN_PATH + \"/images\")\n","file_copy(validation_label_list, VALIDATION_PATH + \"/labels\")\n","file_copy(validation_image_list, VALIDATION_PATH + \"/images\")"],"id":"saORJr0OBY-l"},{"cell_type":"markdown","metadata":{"id":"HzSe0SSnoKXM"},"source":["## 3. Yaml 파일 생성하기\n","* Yaml이란? xml과 json 포맷과 같이 타 시스템 간에 데이터를 주고받을 때 약속된 포맷(규칙)이 정의되어있는 파일 형식<br>\n","https://abluesnake.tistory.com/128<br>"],"id":"HzSe0SSnoKXM"},{"cell_type":"markdown","metadata":{"id":"IiRgiZV4oKXM"},"source":["<font color=\"green\">[실습문제]</font> 6. train, validation 이미지 경로를 txt 파일로 저장하기 \n","- yolov5 학습을 위해 data.yaml 파일 내 \n","train, val의 값을 이미지 파일들의 경로를 저장한 .txt 파일로 변경이 필요합니다.\n","```\n","with open(DATA_PATH + '/train.txt', 'w') as f:\n","      f.write('\\n'.join(train_image_list) + '\\n')\n","```\n"],"id":"IiRgiZV4oKXM"},{"cell_type":"code","execution_count":null,"metadata":{"id":"Bvq8D4QboM68"},"outputs":[],"source":["# 실습해보세요\n","train_image_list = glob.glob(TRAIN_PATH + \"/*/*.jpg\")\n","validation_image_list = glob.glob(VALIDATION_PATH + \"/*/*.jpg\")\n","\n","\n","with open(DATA_PATH + '/train.txt', 'w') as f:\n","    f.write('\\n'.join(train_image_list) + '\\n')\n","\n","with open(DATA_PATH + '/validation.txt', 'w') as f:\n","    f.write('\\n'.join(validation_image_list) + '\\n')"],"id":"Bvq8D4QboM68"},{"cell_type":"markdown","metadata":{"id":"bHhUf2Y4obSV"},"source":["<font color=\"green\">[실습문제]</font> 7. \"data.yaml\" 파일을 생성하고 내 라벨 클래스들과 경로를 입력해주세요.\n","* data.yaml 파일은 딕셔너리 형태로 되어 있습니다.\n","> - 데이터 경로 <br>\n","> train : DATA_PATH + '/train.txt'<br>\n","> val : DATA_PATH + '/validation.txt'<br>\n","> - 클래스 수 <br>\n","> nc: 2<br>\n","> - 클래스 이름 <br>\n","> names: ['Helmet', 'Person'] <br>\n","```\n","data = {\n","              'train' : ,\n","              'val' : ,\n","              'nc' : ,\n","              'names' : [  ]       \n","}\n","```\n","* yaml 파일은 dump() 메소드로 쓰기 가능합니다.\n","```\n","with open(DATA_PATH + '/data.yaml', 'w') as f:\n","        yaml.dump(data, f)\n","```\n"],"id":"bHhUf2Y4obSV"},{"cell_type":"code","execution_count":null,"metadata":{"id":"GKq1-6sEF9xc"},"outputs":[],"source":["# 라이브러리 불러오기\n","import yaml"],"id":"GKq1-6sEF9xc"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1666264340249,"user":{"displayName":"석재민","userId":"11162518966479505622"},"user_tz":-540},"id":"eE8D2BB6roG7","outputId":"554e9e62-9313-4981-c2eb-d74e4ce27dd1"},"outputs":[{"name":"stdout","output_type":"stream","text":["{'train': '/content/data/train.txt', 'val': '/content/data/validation.txt', 'nc': 2, 'names': ['Helmet', 'Person']}\n"]}],"source":["# 실습해보세요.\n","data = {\n","          'train' : DATA_PATH + '/train.txt',\n","          'val' : DATA_PATH + '/validation.txt',\n","          'nc' : 2 ,\n","          'names' : [ 'Helmet', 'Person' ]       \n","}\n","\n","with open(DATA_PATH + '/data.yaml', 'w') as f:\n","  yaml.dump(data, f)\n","\n","print(data)"],"id":"eE8D2BB6roG7"},{"cell_type":"markdown","metadata":{"id":"f0oi8s0DLcFX"},"source":["## 4. Yolov5 를 이용한 모델 학습\n","> https://github.com/ultralytics/yolov5/wiki/Train-Custom-Data/<br>\n","> ○ [Command] \n","```# 코드로 형식 지정됨\n"," !python train.py --img 640 --epochs 3 --data coco.yaml --weights yolov5n.pt --batch 128 \n","                                                                  yolov5s            64\n","                                                                  yolov5m            40\n","                                                                  yolov5l            24\n","                                                                  yolov5x            16\n","```\n","\n","> ○ [Properties]\n",">> --img: 입력 이미지 크기 <br>\n",">> --batch: 배치 크기 <br>\n",">> --epochs: 학습 epoch 수 <br>\n",">> --data: data.yaml 파일 경로 <br>\n",">> --cfg: 모델 구성 지정 <br>\n",">> --weights: 가중치에 대한 사용자 정의 경로를 지정<br>\n",">> --name: 모델이 저장 될 폴더 이름 <br>\n",">> --nosave: 최종 체크포인트만 저장<br>\n",">> --cache: 더 빠른 학습을 위해 이미지를 캐시<br>\n","\n","> ○ [Select Model]<br>\n","><img src=\"https://github.com/ultralytics/yolov5/releases/download/v1.0/model_comparison.png\" width=\"640px\">"],"id":"f0oi8s0DLcFX"},{"cell_type":"markdown","metadata":{"id":"szLs-keis-q7"},"source":["<font color=\"green\">[실습문제]</font> 8. Yolov5s(small) 모델을 활용하여 학습하세요.\n","> img size : 416 <br>\n","> batch size : 16 <br>\n","> epochs : 5 <br>\n","> data : /content/data/data.yaml <br>\n","> weights : yolov5s.pt <br>\n","> name : OID_helmet_data_detection <br>"],"id":"szLs-keis-q7"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1666264494603,"user":{"displayName":"석재민","userId":"11162518966479505622"},"user_tz":-540},"id":"GLWAsKIMTaMp","outputId":"3e111208-aed8-4da8-db65-c8b3b20ac1fd"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/yolov5\n"]}],"source":["# 실행 경로 이동\n","%pwd\n","%cd /content/yolov5"],"id":"GLWAsKIMTaMp"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":110595,"status":"ok","timestamp":1666264607672,"user":{"displayName":"석재민","userId":"11162518966479505622"},"user_tz":-540},"id":"dgqhwjxeLItu","outputId":"a889ade9-4328-426f-dd0b-69f2fbbd1174"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5s.pt, cfg=, data=/content/data/data.yaml, hyp=data/hyps/hyp.scratch-low.yaml, epochs=5, batch_size=16, imgsz=416, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs/train, name=OID_helmet_data_detection, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n","\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 ✅\n","YOLOv5 🚀 v6.2-203-g6371de8 Python-3.7.15 torch-1.12.1+cu113 CUDA:0 (Tesla T4, 15110MiB)\n","\n","\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n","\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLOv5 🚀 in ClearML\n","\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 🚀 runs in Comet\n","\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n","Downloading https://ultralytics.com/assets/Arial.ttf to /root/.config/Ultralytics/Arial.ttf...\n","100% 755k/755k [00:00<00:00, 155MB/s]\n","Downloading https://github.com/ultralytics/yolov5/releases/download/v6.2/yolov5s.pt to yolov5s.pt...\n","100% 14.1M/14.1M [00:00<00:00, 279MB/s]\n","\n","Overriding model.yaml nc=80 with nc=2\n","\n","                 from  n    params  module                                  arguments                     \n","  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n","  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n","  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n","  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n","  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n","  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n","  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n","  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n","  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n","  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n"," 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n"," 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n"," 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n"," 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n"," 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n"," 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n"," 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n"," 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n"," 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n"," 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n"," 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n"," 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n"," 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n"," 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n"," 24      [17, 20, 23]  1     18879  models.yolo.Detect                      [2, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n","Model summary: 214 layers, 7025023 parameters, 7025023 gradients, 16.0 GFLOPs\n","\n","Transferred 343/349 items from yolov5s.pt\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n","\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 57 weight(decay=0.0), 60 weight(decay=0.0005), 60 bias\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n","\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/content/data/train' images and labels...199 found, 0 missing, 0 empty, 0 corrupt: 100% 199/199 [00:00<00:00, 2038.61it/s]\n","\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/data/train.cache\n","\u001b[34m\u001b[1mval: \u001b[0mScanning '/content/data/validation' images and labels...99 found, 0 missing, 0 empty, 0 corrupt: 100% 99/99 [00:00<00:00, 1383.00it/s]\n","\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/data/validation.cache\n","\n","\u001b[34m\u001b[1mAutoAnchor: \u001b[0m4.88 anchors/target, 0.997 Best Possible Recall (BPR). Current anchors are a good fit to dataset ✅\n","Plotting labels to runs/train/OID_helmet_data_detection/labels.jpg... \n","Image sizes 416 train, 416 val\n","Using 2 dataloader workers\n","Logging results to \u001b[1mruns/train/OID_helmet_data_detection\u001b[0m\n","Starting training for 5 epochs...\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","        0/4      1.71G     0.1189    0.04036    0.02935         85        416: 100% 13/13 [00:10<00:00,  1.21it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 4/4 [00:04<00:00,  1.21s/it]\n","                   all         99        224    0.00549      0.337    0.00449    0.00155\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","        1/4       2.1G     0.1084    0.04796    0.02689        133        416: 100% 13/13 [00:07<00:00,  1.69it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 4/4 [00:02<00:00,  1.40it/s]\n","                   all         99        224     0.0254     0.0868     0.0137    0.00375\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","        2/4       2.1G    0.09907    0.05262     0.0242        105        416: 100% 13/13 [00:09<00:00,  1.35it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 4/4 [00:02<00:00,  1.74it/s]\n","                   all         99        224      0.144      0.141     0.0682     0.0187\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","        3/4       2.1G     0.0888    0.04885    0.02163         44        416: 100% 13/13 [00:08<00:00,  1.52it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 4/4 [00:02<00:00,  1.56it/s]\n","                   all         99        224      0.628      0.128     0.0808      0.029\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","        4/4       2.1G     0.0856    0.05724    0.01896        144        416: 100% 13/13 [00:08<00:00,  1.49it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 4/4 [00:02<00:00,  1.67it/s]\n","                   all         99        224       0.63      0.148     0.0935     0.0415\n","\n","5 epochs completed in 0.019 hours.\n","Optimizer stripped from runs/train/OID_helmet_data_detection/weights/last.pt, 14.3MB\n","Optimizer stripped from runs/train/OID_helmet_data_detection/weights/best.pt, 14.3MB\n","\n","Validating runs/train/OID_helmet_data_detection/weights/best.pt...\n","Fusing layers... \n","Model summary: 157 layers, 7015519 parameters, 0 gradients, 15.8 GFLOPs\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 4/4 [00:02<00:00,  1.41it/s]\n","                   all         99        224      0.633      0.148     0.0934     0.0415\n","                Helmet         99         79          1          0     0.0284     0.0138\n","                Person         99        145      0.266      0.295      0.158     0.0693\n","Results saved to \u001b[1mruns/train/OID_helmet_data_detection\u001b[0m\n"]}],"source":["# 실습해보세요.\n","!python train.py --img 416 --batch 16 --epochs 5 --data /content/data/data.yaml --weights yolov5s.pt --name OID_helmet_data_detection"],"id":"dgqhwjxeLItu"},{"cell_type":"markdown","metadata":{"id":"d3G--l-Xf8ZG"},"source":["## 5. 모델 성능 평가\n","> Yolo에서는 모델의 성능(정확도)를 Mean Average Precision(mAP)를 통해 확인합니다. <br>\n","mAP가 높을수록 정확하고, 작을수록 부정확합니다. <br>\n","> AP를 계산할 때, precision-recall,IoU 와 연관이 있습니다. <br>\n"],"id":"d3G--l-Xf8ZG"},{"cell_type":"markdown","metadata":{"id":"iCKM0MCGe0NQ"},"source":["## 6. Test 데이터 추론하기 \n","* 해당 결과는 runs/detect/exp/ 위치에 저장됩니다.\n","> ○ [Command] \n","``` # 코드로 형식 지정됨\n","!python detect.py --source 0  # webcam\n","                           img.jpg  # image\n","                           vid.mp4  # video\n","                           screen  # screenshot\n","                           path/  # directory\n","                           'path/*.jpg'  # glob\n","                           'https://youtu.be/Zgi9g1ksQHc'  # YouTube\n","                           'rtsp://example.com/media.mp4'  # RTSP, RTMP, HTTP stream\n","```\n","> ○ [Properties] \n",">> -- source : test 데이터(이미지, 영상 파일 혹은 폴더) 경로 <br>\n",">> -- weights : 학습이 완료된 weight 파일 경로 (pt 형식) <br>\n",">> -- conf : IOU_threshold 값 (0 ~ 1 사이의 값)\n"],"id":"iCKM0MCGe0NQ"},{"cell_type":"markdown","metadata":{"id":"XpuLW8yAHN-W"},"source":["* TEST 데이터 다운로드하기(아래의 코드를 실행하세요)\n"],"id":"XpuLW8yAHN-W"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1666264678352,"user":{"displayName":"석재민","userId":"11162518966479505622"},"user_tz":-540},"id":"Kgxu2agF2cAr","outputId":"40fba703-5a0b-4abd-fc04-8177fc5c9beb"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content\n"]}],"source":["# 현재 디렉토리 확인\n","%pwd\n","%cd /content"],"id":"Kgxu2agF2cAr"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2933,"status":"ok","timestamp":1666264683629,"user":{"displayName":"석재민","userId":"11162518966479505622"},"user_tz":-540},"id":"JnEqBQ8C2MeH","outputId":"56c03cbc-f8dc-4082-bc3d-390a78e80c21"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: gdown in /usr/local/lib/python3.7/dist-packages (4.4.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from gdown) (4.64.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from gdown) (3.8.0)\n","Requirement already satisfied: requests[socks] in /usr/local/lib/python3.7/dist-packages (from gdown) (2.23.0)\n","Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from gdown) (4.6.3)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from gdown) (1.15.0)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (1.25.11)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (2022.9.24)\n","Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (1.7.1)\n"]}],"source":["!pip install gdown"],"id":"JnEqBQ8C2MeH"},{"cell_type":"code","execution_count":null,"metadata":{"id":"AcNkxlOD2SYd"},"outputs":[],"source":["import gdown\n","import zipfile"],"id":"AcNkxlOD2SYd"},{"cell_type":"code","execution_count":null,"metadata":{"id":"ddT3ob9cBZX1"},"outputs":[],"source":["test_file_id = \"14PsLrMhL2v7n3dYjv2JOFWF6iIUFYhyQ\"\n","\n","def goolge_drive_download (file_id): \n","  google_path = 'https://drive.google.com/uc?id='\n","  output_name = 'download_file.zip'\n","\n","  gdown.download(google_path+file_id,output_name,quiet=False)\n","\n","  zip_file = \"/content/download_file.zip\"\n","\n","  \n","  with zipfile.ZipFile(zip_file) as z:\n","    z.extractall(\"/content\")\n","\n","  os.remove(zip_file) \n"],"id":"ddT3ob9cBZX1"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4186,"status":"ok","timestamp":1666264696192,"user":{"displayName":"석재민","userId":"11162518966479505622"},"user_tz":-540},"id":"3G3jHfuW2XnO","outputId":"087184f4-541d-46cd-8650-73176e97feb8"},"outputs":[{"name":"stderr","output_type":"stream","text":["Downloading...\n","From: https://drive.google.com/uc?id=14PsLrMhL2v7n3dYjv2JOFWF6iIUFYhyQ\n","To: /content/download_file.zip\n","100%|██████████| 9.86M/9.86M [00:00<00:00, 61.1MB/s]\n"]}],"source":["goolge_drive_download(test_file_id)"],"id":"3G3jHfuW2XnO"},{"cell_type":"markdown","metadata":{"id":"F4I-AY3bp0Pb"},"source":["<font color=\"green\">[실습문제]</font> 9-1. 이미지를 소스로 한 객체 검출하기 \n","> 경로 \"TEST_IMAGE_PATH\" 의 이미지 파일들의 객체를 검출해 보세요.  \n","> [조건] \n","> ① img size : 416, ② IOU Threshold : 0.5, ③ 모델 weights : best.pt"],"id":"F4I-AY3bp0Pb"},{"cell_type":"code","execution_count":null,"metadata":{"id":"av7GzbrdH2HP"},"outputs":[],"source":["# 경로 설정\n","TEST_IMAGE_PATH = \"/content/data/test/images\""],"id":"av7GzbrdH2HP"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7489,"status":"ok","timestamp":1666264893529,"user":{"displayName":"석재민","userId":"11162518966479505622"},"user_tz":-540},"id":"J216grQfp0Pb","outputId":"079eb8f0-513d-4cc1-b2c2-8cfefd07cbaa"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/yolov5\n","\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/content/yolov5/runs/train/OID_helmet_data_detection/weights/best.pt'], source=/content/data/test/images, data=data/coco128.yaml, imgsz=[416, 416], conf_thres=0.5, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n","YOLOv5 🚀 v6.2-203-g6371de8 Python-3.7.15 torch-1.12.1+cu113 CUDA:0 (Tesla T4, 15110MiB)\n","\n","Fusing layers... \n","Model summary: 157 layers, 7015519 parameters, 0 gradients, 15.8 GFLOPs\n","image 1/12 /content/data/test/images/test_image_01.jpg: 256x416 (no detections), 12.1ms\n","image 2/12 /content/data/test/images/test_image_02.jpg: 256x416 (no detections), 7.8ms\n","image 3/12 /content/data/test/images/test_image_03.jpg: 256x416 2 Persons, 7.3ms\n","image 4/12 /content/data/test/images/test_image_04.jpg: 256x416 (no detections), 8.0ms\n","image 5/12 /content/data/test/images/test_image_05.jpg: 256x416 (no detections), 7.9ms\n","image 6/12 /content/data/test/images/test_image_06.jpg: 256x416 (no detections), 7.8ms\n","image 7/12 /content/data/test/images/test_image_07.jpg: 256x416 1 Person, 7.8ms\n","image 8/12 /content/data/test/images/test_image_08.jpg: 256x416 (no detections), 7.8ms\n","image 9/12 /content/data/test/images/test_image_09.jpg: 256x416 (no detections), 7.2ms\n","image 10/12 /content/data/test/images/test_image_10.jpg: 256x416 (no detections), 7.8ms\n","image 11/12 /content/data/test/images/test_image_11.jpg: 256x416 (no detections), 7.6ms\n","image 12/12 /content/data/test/images/test_image_12.jpg: 256x416 1 Person, 7.3ms\n","Speed: 0.3ms pre-process, 8.0ms inference, 0.5ms NMS per image at shape (1, 3, 416, 416)\n","Results saved to \u001b[1mruns/detect/exp\u001b[0m\n"]}],"source":["# 실습해보세요\n","%cd /content/yolov5\n","\n","!python detect.py --source '{TEST_IMAGE_PATH}' --weights /content/yolov5/runs/train/OID_helmet_data_detection/weights/best.pt --img 416 --conf 0.5\n"],"id":"J216grQfp0Pb"},{"cell_type":"markdown","metadata":{"id":"7ow6CvdOOLcw"},"source":["<font color=\"green\">[실습문제]</font> 9-2. detect가 완료된 이미지를 확인해 보세요.\n","\n","\n"],"id":"7ow6CvdOOLcw"},{"cell_type":"code","execution_count":75,"metadata":{"executionInfo":{"elapsed":500,"status":"ok","timestamp":1666267574472,"user":{"displayName":"석재민","userId":"11162518966479505622"},"user_tz":-540},"id":"c6VHAuI2I-Rb"},"outputs":[],"source":["# 필요 라이브러리 불러오기\n","from PIL import Image               # to load images\n","from IPython.display import display # to display images"],"id":"c6VHAuI2I-Rb"},{"cell_type":"code","execution_count":84,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1KjIAOarGGv1uabgA0aSGuKGomxrYKitr"},"executionInfo":{"elapsed":46671,"status":"ok","timestamp":1666267864483,"user":{"displayName":"석재민","userId":"11162518966479505622"},"user_tz":-540},"id":"_eJlfDx0Bz9S","outputId":"323f8a86-8ed2-4cba-8e5e-c9770bfb7ae8"},"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}],"source":["# 실습해보세요.\n","detect_image_path = \"/content/yolov5/runs/detect/exp\"  #detect가 완료된 파일의 경로\n","\n","for i in glob.glob(detect_image_path + '/*.jpg'):\n","  img = Image.open(i)\n","  img_resize = img.resize((640, 360))\n","  display(img_resize)\n","  print('\\n')\n"],"id":"_eJlfDx0Bz9S"},{"cell_type":"markdown","metadata":{"id":"u8l3c5namfEs"},"source":["<font color=\"green\">[실습문제]</font> 10-1. 동영상을 소스로 한 객체 검출하기 \n","> 경로 \"TEST_VIDEO_PATH\" 의 이미지 파일들의 객체를 검출해 보세요.  \n","> [조건] \n","> ① IOU Threshold : 0.5, ② 모델 weights : best.pt "],"id":"u8l3c5namfEs"},{"cell_type":"code","execution_count":null,"metadata":{"id":"pZ0EJ9cnmeKX"},"outputs":[],"source":["# 실습해보세요\n","!python detect.py --source '{TEST_VIDEO_PATH}' --weights /content/yolov5/runs/train/OID_helmet_data_detection/weights/best.pt --img 416 --conf 0.5"],"id":"pZ0EJ9cnmeKX"},{"cell_type":"markdown","metadata":{"id":"bXLmOotHpkjl"},"source":["<font color=\"green\">[실습문제]</font> 10-2. detect가 완료된 동영상을 확인해 보세요.\n","- 아래의 코드는 colab에서 비디오 파일을 실행하기 위해 video 파일을 압축하고 HTML video 속성으로 출력하는 코드입니다. \n","- detect_video(detect가 완료된 비디오 파일) 의 경로만 변경하시고 그대로 실행하시면 되겠습니다."],"id":"bXLmOotHpkjl"},{"cell_type":"code","execution_count":null,"metadata":{"id":"DTsF2qXVpkIq"},"outputs":[],"source":["# 실습해보세요.\n","detect_video = '/content/test_video_01.mp4' # 경로 수정\n","compressed_video = '' # 압축이 완료된 이후 저장되는 파일 경로 변수\n","\n","# 비디오 데이터 압축 (Colab에서 실행 목적)\n","def video_compressing(detect_video):  \n","  compressed_video = detect_video[:-4] + \"_compressed.mp4\"\n","  os.system(f\"ffmpeg -i {detect_video} -vcodec libx264 {compressed_video}\")\n","\n","  return compressed_video \n"],"id":"DTsF2qXVpkIq"},{"cell_type":"code","execution_count":null,"metadata":{"id":"LzzZg93a-Zjn"},"outputs":[],"source":["compressed_video = video_compressing(detect_video)\n","\n","from IPython.display import HTML\n","from base64 import b64encode\n","\n","mp4 = open(compressed_video,'rb').read()\n","data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n","HTML(\"\"\"\n","<video width=400 controls>\n","    <source src=\"%s\" type=\"video/mp4\">\n","</video>\n","\"\"\" % data_url)"],"id":"LzzZg93a-Zjn"}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"}},"nbformat":4,"nbformat_minor":5}