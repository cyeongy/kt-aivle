{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "1_1_Quick_Keras_Functional.ipynb",
   "provenance": [],
   "collapsed_sections": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HZc219MFFibh",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Keras로 Linear&Logistic Regression 맛보기!\n",
    "\n",
    "#### 실습목표<br>\n",
    "1. keras의 모델링 아이디어를 이해한다.\n",
    "2. 모든 코드를 이해한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dwEdLgZpFibi",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Quick Linear Regression!"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Lbold6iIS8E1",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import numpy as np"
   ],
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "QvObzQ1MFibj",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "x = np.array(range(0,20)) \n",
    "y = x * 2 -1\n",
    "\n",
    "print(x)\n",
    "print(y)"
   ],
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[-1  1  3  5  7  9 11 13 15 17 19 21 23 25 27 29 31 33 35 37]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "iUqZACd2IRcn",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "# 혹시 이미 그려둔 그래프가 있다면 날려줘!\n",
    "keras.backend.clear_session()\n",
    "\n",
    "# 레이어들을 사슬로 연결하 듯이 연결!\n",
    "input_layer = keras.layers.Input(shape=(1,))\n",
    "output_layer = keras.layers.Dense(1)(input_layer)\n",
    "\n",
    "# 모델의 시작과 끝을 지정\n",
    "model = keras.models.Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "# 컴파일 해주렴\n",
    "model.compile(loss = 'mse', optimizer = 'adam')"
   ],
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "s1UM3mOzLTeb",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "# 데이터를 넣어서 학습시키자!\n",
    "model.fit(x, y, epochs=10, verbose=1)"
   ],
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 156.4616\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 156.1632\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 155.8650\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 0s/step - loss: 155.5671\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 0s/step - loss: 155.2696\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 154.9723\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 0s/step - loss: 154.6754\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 0s/step - loss: 154.3787\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 154.0824\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 0s/step - loss: 153.7865\n"
     ]
    },
    {
     "data": {
      "text/plain": "<tensorflow.python.keras.callbacks.History at 0x1c8862ba6d0>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "FZH5RHQivTiJ",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "# 결과 출력해줘!\n",
    "print(y)\n",
    "print(model.predict(x).reshape(-1,) )"
   ],
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1  1  3  5  7  9 11 13 15 17 19 21 23 25 27 29 31 33 35 37]\n",
      "[9.9967839e-03 8.1847483e-01 1.6269529e+00 2.4354310e+00 3.2439091e+00\n",
      " 4.0523872e+00 4.8608651e+00 5.6693435e+00 6.4778214e+00 7.2862992e+00\n",
      " 8.0947771e+00 8.9032555e+00 9.7117329e+00 1.0520211e+01 1.1328690e+01\n",
      " 1.2137167e+01 1.2945645e+01 1.3754124e+01 1.4562601e+01 1.5371079e+01]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zvqPQxmgFibo",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Now, Your turn!"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "xlxFydqCva9k",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "wIFzEwY2PWpX",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "x = np.array(range(0,20))\n",
    "y = x * (-3) + 10\n",
    "\n",
    "print(x)\n",
    "print(y)"
   ],
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "[ 10   7   4   1  -2  -5  -8 -11 -14 -17 -20 -23 -26 -29 -32 -35 -38 -41\n",
      " -44 -47]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "pNul2_K5PhGi",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "# 혹시 이미 그려둔 그래프가 있다면 날려줘!\n",
    "keras.backend.clear_session()\n",
    "\n",
    "# 레이어들을 사슬로 연결하 듯이 연결!\n",
    "input_layer = keras.layers.Input(shape=(1,))\n",
    "output_layer = keras.layers.Dense(1)(input_layer)\n",
    "\n",
    "# 모델의 시작과 끝을 지정\n",
    "model = keras.models.Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "# 컴파일 해주렴\n",
    "model.compile(loss = 'mse', optimizer = 'adam')"
   ],
   "execution_count": 7,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1/1 [==============================] - 0s 999us/step - loss: 853.2104\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 852.5280\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 0s/step - loss: 851.8457\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 851.1639\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 999us/step - loss: 850.4822\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 849.8009\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 0s/step - loss: 849.1198\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 848.4391\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 847.7588\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 847.0788\n"
     ]
    },
    {
     "data": {
      "text/plain": "<tensorflow.python.keras.callbacks.History at 0x1c891b639d0>"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터를 넣어서 학습시키자!\n",
    "model.fit(x, y, epochs=10, verbose=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 10   7   4   1  -2  -5  -8 -11 -14 -17 -20 -23 -26 -29 -32 -35 -38 -41\n",
      " -44 -47]\n",
      "[-0.00999851  0.33585024  0.681699    1.0275476   1.3733964   1.7192452\n",
      "  2.0650938   2.4109426   2.7567914   3.1026402   3.448489    3.7943375\n",
      "  4.1401863   4.4860353   4.831884    5.177733    5.5235815   5.86943\n",
      "  6.215279    6.5611277 ]\n"
     ]
    }
   ],
   "source": [
    "# 결과 출력해줘!\n",
    "print(y)\n",
    "print(model.predict(x).reshape(-1,) )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "zhr1VsJzQcGI",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CMfaYMFCTz2d",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Quick Logistic Regression!"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "OmGKbCiATz2e",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import numpy as np"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "yzweU4sRTz2g",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "x = np.array(range(0,20)) \n",
    "y = np.array([0]*10 + [1]*10)\n",
    "\n",
    "print(x)\n",
    "print(y)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "wiQzDaBzTz2j",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "# 혹시 이미 그려둔 그래프가 있다면 날려줘!\n",
    "keras.backend.clear_session()\n",
    "\n",
    "# 레이어들을 사슬로 연결하 듯이 연결!\n",
    "input_layer = keras.layers.Input(shape=(1,))\n",
    "output_layer = keras.layers.Dense(1, activation='sigmoid')(input_layer)\n",
    "\n",
    "# 모델의 시작과 끝을 지정\n",
    "model = keras.models.Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "\n",
    "# 컴파일 해주렴\n",
    "model.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics=['accuracy'])"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "b_FXYQ7fTz2l",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "# 데이터를 넣어서 학습시키자!\n",
    "model.fit(x, y, epochs=10, verbose=1)\n",
    "\n",
    "# 결과 출력해줘!\n",
    "print(y)\n",
    "print(model.predict(x).reshape(-1,) )"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bqJtsDjtTz2n",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Now, Your turn!"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "-ihUgWzFvkPL",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "IGSN3QAPTz2o",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "x = np.array(range(0,40)) \n",
    "y = np.array([0]*20 + [1]*20)\n",
    "print(x)\n",
    "print(y)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Ma61XgWYUMPi",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "nniSdDU1UM29",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "BNKQQzy5UNFm",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "boston = load_boston()\n",
    "\n",
    "x = boston.data\n",
    "y = boston.target\n",
    "\n",
    "x.shape, y.shape"
   ],
   "execution_count": 11,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\allsa\\anaconda3\\envs\\kt-aivle\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function load_boston is deprecated; `load_boston` is deprecated in 1.0 and will be removed in 1.2.\n",
      "\n",
      "    The Boston housing prices dataset has an ethical problem. You can refer to\n",
      "    the documentation of this function for further details.\n",
      "\n",
      "    The scikit-learn maintainers therefore strongly discourage the use of this\n",
      "    dataset unless the purpose of the code is to study and educate about\n",
      "    ethical issues in data science and machine learning.\n",
      "\n",
      "    In this special case, you can fetch the dataset from the original\n",
      "    source::\n",
      "\n",
      "        import pandas as pd\n",
      "        import numpy as np\n",
      "\n",
      "        data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
      "        raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
      "        data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
      "        target = raw_df.values[1::2, 2]\n",
      "\n",
      "    Alternative datasets include the California housing dataset (i.e.\n",
      "    :func:`~sklearn.datasets.fetch_california_housing`) and the Ames housing\n",
      "    dataset. You can load the datasets as follows::\n",
      "\n",
      "        from sklearn.datasets import fetch_california_housing\n",
      "        housing = fetch_california_housing()\n",
      "\n",
      "    for the California housing dataset and::\n",
      "\n",
      "        from sklearn.datasets import fetch_openml\n",
      "        housing = fetch_openml(name=\"house_prices\", as_frame=True)\n",
      "\n",
      "    for the Ames housing dataset.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": "((506, 13), (506,))"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "# Clear Keras backend\n",
    "keras.backend.clear_session()\n",
    "\n",
    "# make layers\n",
    "il = keras.layers.Input(shape=(13,))\n",
    "ol = keras.layers.Dense(1)(il)\n",
    "\n",
    "# make model\n",
    "model = keras.models.Model(inputs=il, outputs=ol)\n",
    "\n",
    "# compile model\n",
    "model.compile(optimizer='adam', loss='mse')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "16/16 [==============================] - 0s 937us/step - loss: 1900.8293\n",
      "Epoch 2/100\n",
      "16/16 [==============================] - 0s 625us/step - loss: 1814.3075\n",
      "Epoch 3/100\n",
      "16/16 [==============================] - 0s 750us/step - loss: 1736.1926\n",
      "Epoch 4/100\n",
      "16/16 [==============================] - 0s 688us/step - loss: 1666.8589\n",
      "Epoch 5/100\n",
      "16/16 [==============================] - 0s 750us/step - loss: 1596.2437\n",
      "Epoch 6/100\n",
      "16/16 [==============================] - 0s 812us/step - loss: 1528.4883\n",
      "Epoch 7/100\n",
      "16/16 [==============================] - 0s 625us/step - loss: 1466.4912\n",
      "Epoch 8/100\n",
      "16/16 [==============================] - 0s 750us/step - loss: 1401.9261\n",
      "Epoch 9/100\n",
      "16/16 [==============================] - 0s 687us/step - loss: 1341.1403\n",
      "Epoch 10/100\n",
      "16/16 [==============================] - 0s 750us/step - loss: 1281.4843\n",
      "Epoch 11/100\n",
      "16/16 [==============================] - 0s 687us/step - loss: 1223.3344\n",
      "Epoch 12/100\n",
      "16/16 [==============================] - 0s 688us/step - loss: 1168.6288\n",
      "Epoch 13/100\n",
      "16/16 [==============================] - 0s 562us/step - loss: 1114.1411\n",
      "Epoch 14/100\n",
      "16/16 [==============================] - 0s 563us/step - loss: 1061.5149\n",
      "Epoch 15/100\n",
      "16/16 [==============================] - 0s 687us/step - loss: 1012.2949\n",
      "Epoch 16/100\n",
      "16/16 [==============================] - 0s 625us/step - loss: 963.5430\n",
      "Epoch 17/100\n",
      "16/16 [==============================] - 0s 625us/step - loss: 919.2473\n",
      "Epoch 18/100\n",
      "16/16 [==============================] - 0s 687us/step - loss: 872.5389\n",
      "Epoch 19/100\n",
      "16/16 [==============================] - 0s 625us/step - loss: 831.9138\n",
      "Epoch 20/100\n",
      "16/16 [==============================] - 0s 625us/step - loss: 790.1434\n",
      "Epoch 21/100\n",
      "16/16 [==============================] - 0s 562us/step - loss: 751.3239\n",
      "Epoch 22/100\n",
      "16/16 [==============================] - 0s 625us/step - loss: 714.8837\n",
      "Epoch 23/100\n",
      "16/16 [==============================] - 0s 625us/step - loss: 680.5487\n",
      "Epoch 24/100\n",
      "16/16 [==============================] - 0s 687us/step - loss: 647.3121\n",
      "Epoch 25/100\n",
      "16/16 [==============================] - 0s 750us/step - loss: 614.8766\n",
      "Epoch 26/100\n",
      "16/16 [==============================] - 0s 750us/step - loss: 584.2032\n",
      "Epoch 27/100\n",
      "16/16 [==============================] - 0s 687us/step - loss: 556.1731\n",
      "Epoch 28/100\n",
      "16/16 [==============================] - 0s 750us/step - loss: 529.7365\n",
      "Epoch 29/100\n",
      "16/16 [==============================] - 0s 625us/step - loss: 503.0322\n",
      "Epoch 30/100\n",
      "16/16 [==============================] - 0s 750us/step - loss: 478.8618\n",
      "Epoch 31/100\n",
      "16/16 [==============================] - 0s 625us/step - loss: 455.8937\n",
      "Epoch 32/100\n",
      "16/16 [==============================] - 0s 625us/step - loss: 433.9058\n",
      "Epoch 33/100\n",
      "16/16 [==============================] - 0s 687us/step - loss: 413.4913\n",
      "Epoch 34/100\n",
      "16/16 [==============================] - 0s 562us/step - loss: 393.8717\n",
      "Epoch 35/100\n",
      "16/16 [==============================] - 0s 562us/step - loss: 375.5033\n",
      "Epoch 36/100\n",
      "16/16 [==============================] - 0s 625us/step - loss: 357.8063\n",
      "Epoch 37/100\n",
      "16/16 [==============================] - 0s 625us/step - loss: 341.1299\n",
      "Epoch 38/100\n",
      "16/16 [==============================] - 0s 688us/step - loss: 326.0704\n",
      "Epoch 39/100\n",
      "16/16 [==============================] - 0s 625us/step - loss: 310.8563\n",
      "Epoch 40/100\n",
      "16/16 [==============================] - 0s 562us/step - loss: 296.9308\n",
      "Epoch 41/100\n",
      "16/16 [==============================] - 0s 625us/step - loss: 283.9309\n",
      "Epoch 42/100\n",
      "16/16 [==============================] - 0s 625us/step - loss: 271.6777\n",
      "Epoch 43/100\n",
      "16/16 [==============================] - 0s 625us/step - loss: 259.8786\n",
      "Epoch 44/100\n",
      "16/16 [==============================] - 0s 687us/step - loss: 248.7592\n",
      "Epoch 45/100\n",
      "16/16 [==============================] - 0s 625us/step - loss: 238.5658\n",
      "Epoch 46/100\n",
      "16/16 [==============================] - 0s 563us/step - loss: 228.5404\n",
      "Epoch 47/100\n",
      "16/16 [==============================] - 0s 687us/step - loss: 219.4169\n",
      "Epoch 48/100\n",
      "16/16 [==============================] - 0s 688us/step - loss: 210.4973\n",
      "Epoch 49/100\n",
      "16/16 [==============================] - 0s 750us/step - loss: 202.3687\n",
      "Epoch 50/100\n",
      "16/16 [==============================] - 0s 750us/step - loss: 194.8329\n",
      "Epoch 51/100\n",
      "16/16 [==============================] - 0s 687us/step - loss: 187.2836\n",
      "Epoch 52/100\n",
      "16/16 [==============================] - 0s 687us/step - loss: 180.4299\n",
      "Epoch 53/100\n",
      "16/16 [==============================] - 0s 687us/step - loss: 174.0196\n",
      "Epoch 54/100\n",
      "16/16 [==============================] - 0s 687us/step - loss: 167.9199\n",
      "Epoch 55/100\n",
      "16/16 [==============================] - 0s 625us/step - loss: 162.3188\n",
      "Epoch 56/100\n",
      "16/16 [==============================] - 0s 625us/step - loss: 156.5299\n",
      "Epoch 57/100\n",
      "16/16 [==============================] - 0s 625us/step - loss: 151.2929\n",
      "Epoch 58/100\n",
      "16/16 [==============================] - 0s 625us/step - loss: 146.6337\n",
      "Epoch 59/100\n",
      "16/16 [==============================] - 0s 625us/step - loss: 141.9297\n",
      "Epoch 60/100\n",
      "16/16 [==============================] - 0s 625us/step - loss: 137.6327\n",
      "Epoch 61/100\n",
      "16/16 [==============================] - 0s 625us/step - loss: 133.4286\n",
      "Epoch 62/100\n",
      "16/16 [==============================] - 0s 625us/step - loss: 129.8083\n",
      "Epoch 63/100\n",
      "16/16 [==============================] - 0s 688us/step - loss: 126.0500\n",
      "Epoch 64/100\n",
      "16/16 [==============================] - 0s 562us/step - loss: 122.5670\n",
      "Epoch 65/100\n",
      "16/16 [==============================] - 0s 687us/step - loss: 119.2844\n",
      "Epoch 66/100\n",
      "16/16 [==============================] - 0s 625us/step - loss: 116.7879\n",
      "Epoch 67/100\n",
      "16/16 [==============================] - 0s 625us/step - loss: 113.4679\n",
      "Epoch 68/100\n",
      "16/16 [==============================] - 0s 687us/step - loss: 110.7418\n",
      "Epoch 69/100\n",
      "16/16 [==============================] - 0s 625us/step - loss: 108.0633\n",
      "Epoch 70/100\n",
      "16/16 [==============================] - 0s 562us/step - loss: 105.6732\n",
      "Epoch 71/100\n",
      "16/16 [==============================] - 0s 625us/step - loss: 103.4509\n",
      "Epoch 72/100\n",
      "16/16 [==============================] - 0s 625us/step - loss: 101.1451\n",
      "Epoch 73/100\n",
      "16/16 [==============================] - 0s 625us/step - loss: 99.1642\n",
      "Epoch 74/100\n",
      "16/16 [==============================] - 0s 625us/step - loss: 97.3038\n",
      "Epoch 75/100\n",
      "16/16 [==============================] - 0s 562us/step - loss: 95.5269\n",
      "Epoch 76/100\n",
      "16/16 [==============================] - 0s 625us/step - loss: 93.7666\n",
      "Epoch 77/100\n",
      "16/16 [==============================] - 0s 625us/step - loss: 92.2266\n",
      "Epoch 78/100\n",
      "16/16 [==============================] - 0s 562us/step - loss: 90.7517\n",
      "Epoch 79/100\n",
      "16/16 [==============================] - 0s 625us/step - loss: 89.2802\n",
      "Epoch 80/100\n",
      "16/16 [==============================] - 0s 687us/step - loss: 87.9453\n",
      "Epoch 81/100\n",
      "16/16 [==============================] - 0s 688us/step - loss: 86.7655\n",
      "Epoch 82/100\n",
      "16/16 [==============================] - 0s 625us/step - loss: 85.6957\n",
      "Epoch 83/100\n",
      "16/16 [==============================] - 0s 562us/step - loss: 84.4812\n",
      "Epoch 84/100\n",
      "16/16 [==============================] - 0s 625us/step - loss: 83.4247\n",
      "Epoch 85/100\n",
      "16/16 [==============================] - 0s 625us/step - loss: 82.4195\n",
      "Epoch 86/100\n",
      "16/16 [==============================] - 0s 625us/step - loss: 81.5390\n",
      "Epoch 87/100\n",
      "16/16 [==============================] - 0s 625us/step - loss: 80.6837\n",
      "Epoch 88/100\n",
      "16/16 [==============================] - 0s 625us/step - loss: 79.8608\n",
      "Epoch 89/100\n",
      "16/16 [==============================] - 0s 625us/step - loss: 79.1202\n",
      "Epoch 90/100\n",
      "16/16 [==============================] - 0s 625us/step - loss: 78.5544\n",
      "Epoch 91/100\n",
      "16/16 [==============================] - 0s 625us/step - loss: 77.6885\n",
      "Epoch 92/100\n",
      "16/16 [==============================] - 0s 688us/step - loss: 77.0415\n",
      "Epoch 93/100\n",
      "16/16 [==============================] - 0s 625us/step - loss: 76.4153\n",
      "Epoch 94/100\n",
      "16/16 [==============================] - 0s 625us/step - loss: 75.9268\n",
      "Epoch 95/100\n",
      "16/16 [==============================] - 0s 625us/step - loss: 75.4603\n",
      "Epoch 96/100\n",
      "16/16 [==============================] - 0s 562us/step - loss: 74.8359\n",
      "Epoch 97/100\n",
      "16/16 [==============================] - 0s 563us/step - loss: 74.3850\n",
      "Epoch 98/100\n",
      "16/16 [==============================] - 0s 687us/step - loss: 73.9075\n",
      "Epoch 99/100\n",
      "16/16 [==============================] - 0s 625us/step - loss: 73.4793\n",
      "Epoch 100/100\n",
      "16/16 [==============================] - 0s 563us/step - loss: 73.1062\n"
     ]
    },
    {
     "data": {
      "text/plain": "<tensorflow.python.keras.callbacks.History at 0x1cb7a204e50>"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x, y, epochs=100, verbose=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[24.  21.6 34.7 33.4 36.2]\n",
      "[23.259842 25.7723   26.076101 22.812723 22.61089 ]\n"
     ]
    }
   ],
   "source": [
    "print(y[:5])\n",
    "print(model.predict(x[:5]).reshape(-1))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "cancer = load_breast_cancer()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "((569, 30), (569,))"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = cancer.data\n",
    "y = cancer.target\n",
    "\n",
    "x.shape, y.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [],
   "source": [
    "# clear keras session\n",
    "keras.backend.clear_session()\n",
    "\n",
    "# make layers\n",
    "il = keras.layers.Input(shape=(30, ))\n",
    "ol = keras.layers.Dense(1, activation='hard_sigmoid')(il)\n",
    "\n",
    "# make model\n",
    "model = keras.models.Model(il, ol)\n",
    "\n",
    "# compile model\n",
    "\n",
    "model.compile(optimizer='adam', loss=keras.losses.binary_crossentropy, metrics=['accuracy'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "18/18 [==============================] - 0s 944us/step - loss: 4.1133 - accuracy: 0.7258\n",
      "Epoch 2/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 4.1091 - accuracy: 0.7241\n",
      "Epoch 3/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 4.1073 - accuracy: 0.7258\n",
      "Epoch 4/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 4.1068 - accuracy: 0.7258\n",
      "Epoch 5/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 4.1064 - accuracy: 0.7258\n",
      "Epoch 6/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 4.0859 - accuracy: 0.7258\n",
      "Epoch 7/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 4.0571 - accuracy: 0.7293\n",
      "Epoch 8/200\n",
      "18/18 [==============================] - 0s 1000us/step - loss: 4.0321 - accuracy: 0.7293\n",
      "Epoch 9/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 3.8182 - accuracy: 0.7329\n",
      "Epoch 10/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 3.7002 - accuracy: 0.7452\n",
      "Epoch 11/200\n",
      "18/18 [==============================] - 0s 944us/step - loss: 3.6047 - accuracy: 0.7557\n",
      "Epoch 12/200\n",
      "18/18 [==============================] - 0s 944us/step - loss: 3.6022 - accuracy: 0.7610\n",
      "Epoch 13/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 3.5812 - accuracy: 0.7610\n",
      "Epoch 14/200\n",
      "18/18 [==============================] - 0s 944us/step - loss: 3.5812 - accuracy: 0.7610\n",
      "Epoch 15/200\n",
      "18/18 [==============================] - 0s 889us/step - loss: 3.5790 - accuracy: 0.7627\n",
      "Epoch 16/200\n",
      "18/18 [==============================] - 0s 1000us/step - loss: 3.5524 - accuracy: 0.7627\n",
      "Epoch 17/200\n",
      "18/18 [==============================] - 0s 944us/step - loss: 3.4118 - accuracy: 0.7663\n",
      "Epoch 18/200\n",
      "18/18 [==============================] - 0s 944us/step - loss: 2.6909 - accuracy: 0.8102\n",
      "Epoch 19/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 1.8962 - accuracy: 0.8559\n",
      "Epoch 20/200\n",
      "18/18 [==============================] - 0s 1000us/step - loss: 1.8212 - accuracy: 0.8594\n",
      "Epoch 21/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 1.7828 - accuracy: 0.8594\n",
      "Epoch 22/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 1.8044 - accuracy: 0.8594\n",
      "Epoch 23/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 1.6535 - accuracy: 0.8524\n",
      "Epoch 24/200\n",
      "18/18 [==============================] - 0s 1000us/step - loss: 1.6405 - accuracy: 0.8594\n",
      "Epoch 25/200\n",
      "18/18 [==============================] - 0s 944us/step - loss: 1.9317 - accuracy: 0.8471\n",
      "Epoch 26/200\n",
      "18/18 [==============================] - 0s 944us/step - loss: 2.0348 - accuracy: 0.8278\n",
      "Epoch 27/200\n",
      "18/18 [==============================] - 0s 944us/step - loss: 1.7409 - accuracy: 0.8401\n",
      "Epoch 28/200\n",
      "18/18 [==============================] - 0s 944us/step - loss: 1.8863 - accuracy: 0.8559\n",
      "Epoch 29/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 1.8538 - accuracy: 0.8647\n",
      "Epoch 30/200\n",
      "18/18 [==============================] - 0s 945us/step - loss: 1.8538 - accuracy: 0.8647\n",
      "Epoch 31/200\n",
      "18/18 [==============================] - 0s 889us/step - loss: 1.8539 - accuracy: 0.8647\n",
      "Epoch 32/200\n",
      "18/18 [==============================] - 0s 945us/step - loss: 1.8536 - accuracy: 0.8647\n",
      "Epoch 33/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 1.8534 - accuracy: 0.8647\n",
      "Epoch 34/200\n",
      "18/18 [==============================] - 0s 944us/step - loss: 1.8533 - accuracy: 0.8647\n",
      "Epoch 35/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 1.8532 - accuracy: 0.8647\n",
      "Epoch 36/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 1.8533 - accuracy: 0.8647\n",
      "Epoch 37/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 1.8530 - accuracy: 0.8647\n",
      "Epoch 38/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 1.8532 - accuracy: 0.8647\n",
      "Epoch 39/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 1.8529 - accuracy: 0.8647\n",
      "Epoch 40/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 1.8529 - accuracy: 0.8647\n",
      "Epoch 41/200\n",
      "18/18 [==============================] - 0s 944us/step - loss: 1.8527 - accuracy: 0.8647\n",
      "Epoch 42/200\n",
      "18/18 [==============================] - 0s 944us/step - loss: 1.8528 - accuracy: 0.8664\n",
      "Epoch 43/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 1.8528 - accuracy: 0.8647\n",
      "Epoch 44/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 1.8528 - accuracy: 0.8664\n",
      "Epoch 45/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 1.8525 - accuracy: 0.8647\n",
      "Epoch 46/200\n",
      "18/18 [==============================] - 0s 1000us/step - loss: 1.8524 - accuracy: 0.8647\n",
      "Epoch 47/200\n",
      "18/18 [==============================] - 0s 944us/step - loss: 1.8529 - accuracy: 0.8664\n",
      "Epoch 48/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 1.8529 - accuracy: 0.8647\n",
      "Epoch 49/200\n",
      "18/18 [==============================] - 2s 117ms/step - loss: 1.8525 - accuracy: 0.8647\n",
      "Epoch 50/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 1.8521 - accuracy: 0.8647\n",
      "Epoch 51/200\n",
      "18/18 [==============================] - 0s 944us/step - loss: 1.8519 - accuracy: 0.8664\n",
      "Epoch 52/200\n",
      "18/18 [==============================] - 0s 889us/step - loss: 1.8519 - accuracy: 0.8664\n",
      "Epoch 53/200\n",
      "18/18 [==============================] - 0s 889us/step - loss: 1.8517 - accuracy: 0.8664\n",
      "Epoch 54/200\n",
      "18/18 [==============================] - 0s 1000us/step - loss: 1.8520 - accuracy: 0.8664\n",
      "Epoch 55/200\n",
      "18/18 [==============================] - 0s 1000us/step - loss: 1.8521 - accuracy: 0.8664\n",
      "Epoch 56/200\n",
      "18/18 [==============================] - 0s 944us/step - loss: 1.8517 - accuracy: 0.8664\n",
      "Epoch 57/200\n",
      "18/18 [==============================] - 0s 1000us/step - loss: 1.8516 - accuracy: 0.8664\n",
      "Epoch 58/200\n",
      "18/18 [==============================] - 0s 944us/step - loss: 1.8515 - accuracy: 0.8664\n",
      "Epoch 59/200\n",
      "18/18 [==============================] - 0s 944us/step - loss: 1.8514 - accuracy: 0.8664\n",
      "Epoch 60/200\n",
      "18/18 [==============================] - 0s 1000us/step - loss: 1.8519 - accuracy: 0.8664\n",
      "Epoch 61/200\n",
      "18/18 [==============================] - 0s 944us/step - loss: 1.8513 - accuracy: 0.8664\n",
      "Epoch 62/200\n",
      "18/18 [==============================] - 0s 889us/step - loss: 1.8513 - accuracy: 0.8664\n",
      "Epoch 63/200\n",
      "18/18 [==============================] - 0s 1000us/step - loss: 1.8513 - accuracy: 0.8664\n",
      "Epoch 64/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 1.8509 - accuracy: 0.8664\n",
      "Epoch 65/200\n",
      "18/18 [==============================] - 0s 944us/step - loss: 1.8509 - accuracy: 0.8664\n",
      "Epoch 66/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 1.8508 - accuracy: 0.8664\n",
      "Epoch 67/200\n",
      "18/18 [==============================] - 0s 944us/step - loss: 1.8510 - accuracy: 0.8664\n",
      "Epoch 68/200\n",
      "18/18 [==============================] - 0s 944us/step - loss: 1.8507 - accuracy: 0.8664\n",
      "Epoch 69/200\n",
      "18/18 [==============================] - 0s 944us/step - loss: 1.8509 - accuracy: 0.8664\n",
      "Epoch 70/200\n",
      "18/18 [==============================] - 0s 889us/step - loss: 1.8505 - accuracy: 0.8664\n",
      "Epoch 71/200\n",
      "18/18 [==============================] - 0s 944us/step - loss: 1.8508 - accuracy: 0.8664\n",
      "Epoch 72/200\n",
      "18/18 [==============================] - 0s 944us/step - loss: 1.8504 - accuracy: 0.8664\n",
      "Epoch 73/200\n",
      "18/18 [==============================] - 0s 944us/step - loss: 1.8502 - accuracy: 0.8664\n",
      "Epoch 74/200\n",
      "18/18 [==============================] - 0s 944us/step - loss: 1.8505 - accuracy: 0.8664\n",
      "Epoch 75/200\n",
      "18/18 [==============================] - 0s 944us/step - loss: 1.8503 - accuracy: 0.8664\n",
      "Epoch 76/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 1.8502 - accuracy: 0.8664\n",
      "Epoch 77/200\n",
      "18/18 [==============================] - 0s 889us/step - loss: 1.8503 - accuracy: 0.8664\n",
      "Epoch 78/200\n",
      "18/18 [==============================] - 0s 944us/step - loss: 1.8498 - accuracy: 0.8664\n",
      "Epoch 79/200\n",
      "18/18 [==============================] - 0s 944us/step - loss: 1.8501 - accuracy: 0.8664\n",
      "Epoch 80/200\n",
      "18/18 [==============================] - 0s 889us/step - loss: 1.8500 - accuracy: 0.8664\n",
      "Epoch 81/200\n",
      "18/18 [==============================] - 0s 944us/step - loss: 1.8497 - accuracy: 0.8664\n",
      "Epoch 82/200\n",
      "18/18 [==============================] - 0s 944us/step - loss: 1.8498 - accuracy: 0.8664\n",
      "Epoch 83/200\n",
      "18/18 [==============================] - 0s 1000us/step - loss: 1.8498 - accuracy: 0.8664\n",
      "Epoch 84/200\n",
      "18/18 [==============================] - 0s 1000us/step - loss: 1.8497 - accuracy: 0.8664\n",
      "Epoch 85/200\n",
      "18/18 [==============================] - 0s 889us/step - loss: 1.8504 - accuracy: 0.8664\n",
      "Epoch 86/200\n",
      "18/18 [==============================] - 0s 1000us/step - loss: 1.8497 - accuracy: 0.8664\n",
      "Epoch 87/200\n",
      "18/18 [==============================] - 0s 944us/step - loss: 1.8493 - accuracy: 0.8664\n",
      "Epoch 88/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 1.8495 - accuracy: 0.8664\n",
      "Epoch 89/200\n",
      "18/18 [==============================] - 0s 944us/step - loss: 1.8495 - accuracy: 0.8664\n",
      "Epoch 90/200\n",
      "18/18 [==============================] - 0s 1000us/step - loss: 1.8491 - accuracy: 0.8664\n",
      "Epoch 91/200\n",
      "18/18 [==============================] - 0s 944us/step - loss: 1.8495 - accuracy: 0.8664\n",
      "Epoch 92/200\n",
      "18/18 [==============================] - 0s 889us/step - loss: 1.8491 - accuracy: 0.8664\n",
      "Epoch 93/200\n",
      "18/18 [==============================] - 0s 944us/step - loss: 1.8495 - accuracy: 0.8664\n",
      "Epoch 94/200\n",
      "18/18 [==============================] - 0s 1000us/step - loss: 1.8488 - accuracy: 0.8664\n",
      "Epoch 95/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 1.8492 - accuracy: 0.8664\n",
      "Epoch 96/200\n",
      "18/18 [==============================] - 0s 889us/step - loss: 1.8492 - accuracy: 0.8664\n",
      "Epoch 97/200\n",
      "18/18 [==============================] - 0s 944us/step - loss: 1.8488 - accuracy: 0.8664\n",
      "Epoch 98/200\n",
      "18/18 [==============================] - 0s 944us/step - loss: 1.8491 - accuracy: 0.8664\n",
      "Epoch 99/200\n",
      "18/18 [==============================] - 0s 1000us/step - loss: 1.8487 - accuracy: 0.8664\n",
      "Epoch 100/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 1.8486 - accuracy: 0.8664\n",
      "Epoch 101/200\n",
      "18/18 [==============================] - 2s 113ms/step - loss: 1.8362 - accuracy: 0.8664\n",
      "Epoch 102/200\n",
      "18/18 [==============================] - 0s 1000us/step - loss: 1.6166 - accuracy: 0.8717\n",
      "Epoch 103/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 1.7119 - accuracy: 0.8559\n",
      "Epoch 104/200\n",
      "18/18 [==============================] - 0s 944us/step - loss: 1.8470 - accuracy: 0.8699\n",
      "Epoch 105/200\n",
      "18/18 [==============================] - 0s 1000us/step - loss: 1.8259 - accuracy: 0.8629\n",
      "Epoch 106/200\n",
      "18/18 [==============================] - 0s 944us/step - loss: 1.8249 - accuracy: 0.8629\n",
      "Epoch 107/200\n",
      "18/18 [==============================] - 0s 889us/step - loss: 1.8246 - accuracy: 0.8664\n",
      "Epoch 108/200\n",
      "18/18 [==============================] - 0s 944us/step - loss: 1.8264 - accuracy: 0.8629\n",
      "Epoch 109/200\n",
      "18/18 [==============================] - 0s 944us/step - loss: 1.8454 - accuracy: 0.8699\n",
      "Epoch 110/200\n",
      "18/18 [==============================] - 0s 944us/step - loss: 1.8445 - accuracy: 0.8717\n",
      "Epoch 111/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 1.8449 - accuracy: 0.8735\n",
      "Epoch 112/200\n",
      "18/18 [==============================] - 0s 944us/step - loss: 1.8445 - accuracy: 0.8735\n",
      "Epoch 113/200\n",
      "18/18 [==============================] - 0s 944us/step - loss: 1.8444 - accuracy: 0.8717\n",
      "Epoch 114/200\n",
      "18/18 [==============================] - 0s 944us/step - loss: 1.8442 - accuracy: 0.8735\n",
      "Epoch 115/200\n",
      "18/18 [==============================] - 0s 944us/step - loss: 1.8442 - accuracy: 0.8717\n",
      "Epoch 116/200\n",
      "18/18 [==============================] - 0s 1000us/step - loss: 1.8442 - accuracy: 0.8735\n",
      "Epoch 117/200\n",
      "18/18 [==============================] - 0s 1000us/step - loss: 1.8440 - accuracy: 0.8735\n",
      "Epoch 118/200\n",
      "18/18 [==============================] - 0s 944us/step - loss: 1.8440 - accuracy: 0.8735\n",
      "Epoch 119/200\n",
      "18/18 [==============================] - 0s 944us/step - loss: 1.8436 - accuracy: 0.8735\n",
      "Epoch 120/200\n",
      "18/18 [==============================] - 0s 833us/step - loss: 1.8441 - accuracy: 0.8717\n",
      "Epoch 121/200\n",
      "18/18 [==============================] - 0s 889us/step - loss: 1.8437 - accuracy: 0.8735\n",
      "Epoch 122/200\n",
      "18/18 [==============================] - 0s 944us/step - loss: 1.8436 - accuracy: 0.8735\n",
      "Epoch 123/200\n",
      "18/18 [==============================] - 0s 944us/step - loss: 1.8433 - accuracy: 0.8735\n",
      "Epoch 124/200\n",
      "18/18 [==============================] - 0s 889us/step - loss: 1.8434 - accuracy: 0.8735\n",
      "Epoch 125/200\n",
      "18/18 [==============================] - 0s 944us/step - loss: 1.8433 - accuracy: 0.8735\n",
      "Epoch 126/200\n",
      "18/18 [==============================] - 0s 1000us/step - loss: 1.8430 - accuracy: 0.8735\n",
      "Epoch 127/200\n",
      "18/18 [==============================] - 0s 944us/step - loss: 1.8431 - accuracy: 0.8735\n",
      "Epoch 128/200\n",
      "18/18 [==============================] - 0s 944us/step - loss: 1.8543 - accuracy: 0.8699\n",
      "Epoch 129/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 2.1211 - accuracy: 0.8453\n",
      "Epoch 130/200\n",
      "18/18 [==============================] - 0s 944us/step - loss: 2.1020 - accuracy: 0.8453\n",
      "Epoch 131/200\n",
      "18/18 [==============================] - 0s 889us/step - loss: 1.7980 - accuracy: 0.8647\n",
      "Epoch 132/200\n",
      "18/18 [==============================] - 0s 889us/step - loss: 1.8185 - accuracy: 0.8717\n",
      "Epoch 133/200\n",
      "18/18 [==============================] - 0s 944us/step - loss: 1.8173 - accuracy: 0.8717\n",
      "Epoch 134/200\n",
      "18/18 [==============================] - 0s 944us/step - loss: 1.8171 - accuracy: 0.8717\n",
      "Epoch 135/200\n",
      "18/18 [==============================] - 0s 944us/step - loss: 1.8169 - accuracy: 0.8717\n",
      "Epoch 136/200\n",
      "18/18 [==============================] - 0s 944us/step - loss: 1.8170 - accuracy: 0.8717\n",
      "Epoch 137/200\n",
      "18/18 [==============================] - 0s 944us/step - loss: 1.8169 - accuracy: 0.8717\n",
      "Epoch 138/200\n",
      "18/18 [==============================] - 0s 944us/step - loss: 1.8167 - accuracy: 0.8717\n",
      "Epoch 139/200\n",
      "18/18 [==============================] - 0s 1000us/step - loss: 1.8167 - accuracy: 0.8717\n",
      "Epoch 140/200\n",
      "18/18 [==============================] - 0s 944us/step - loss: 1.8165 - accuracy: 0.8717\n",
      "Epoch 141/200\n",
      "18/18 [==============================] - 0s 889us/step - loss: 1.8164 - accuracy: 0.8717\n",
      "Epoch 142/200\n",
      "18/18 [==============================] - 0s 889us/step - loss: 1.8166 - accuracy: 0.8717\n",
      "Epoch 143/200\n",
      "18/18 [==============================] - 0s 944us/step - loss: 1.8164 - accuracy: 0.8717\n",
      "Epoch 144/200\n",
      "18/18 [==============================] - 0s 889us/step - loss: 1.8162 - accuracy: 0.8717\n",
      "Epoch 145/200\n",
      "18/18 [==============================] - 0s 944us/step - loss: 1.8161 - accuracy: 0.8717\n",
      "Epoch 146/200\n",
      "18/18 [==============================] - 0s 889us/step - loss: 1.8164 - accuracy: 0.8717\n",
      "Epoch 147/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 1.8161 - accuracy: 0.8717\n",
      "Epoch 148/200\n",
      "18/18 [==============================] - 0s 944us/step - loss: 1.8160 - accuracy: 0.8717\n",
      "Epoch 149/200\n",
      "18/18 [==============================] - 0s 1000us/step - loss: 1.8159 - accuracy: 0.8717\n",
      "Epoch 150/200\n",
      "18/18 [==============================] - 0s 944us/step - loss: 1.8158 - accuracy: 0.8717\n",
      "Epoch 151/200\n",
      "18/18 [==============================] - 0s 889us/step - loss: 1.8159 - accuracy: 0.8717\n",
      "Epoch 152/200\n",
      "18/18 [==============================] - 0s 944us/step - loss: 1.8157 - accuracy: 0.8717\n",
      "Epoch 153/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 1.8157 - accuracy: 0.8717\n",
      "Epoch 154/200\n",
      "18/18 [==============================] - 2s 111ms/step - loss: 1.8155 - accuracy: 0.8717\n",
      "Epoch 155/200\n",
      "18/18 [==============================] - 0s 944us/step - loss: 1.8157 - accuracy: 0.8717\n",
      "Epoch 156/200\n",
      "18/18 [==============================] - 0s 944us/step - loss: 1.8154 - accuracy: 0.8717\n",
      "Epoch 157/200\n",
      "18/18 [==============================] - 0s 944us/step - loss: 1.8153 - accuracy: 0.8717\n",
      "Epoch 158/200\n",
      "18/18 [==============================] - 0s 944us/step - loss: 1.8157 - accuracy: 0.8717\n",
      "Epoch 159/200\n",
      "18/18 [==============================] - 0s 944us/step - loss: 1.8155 - accuracy: 0.8717\n",
      "Epoch 160/200\n",
      "18/18 [==============================] - 0s 889us/step - loss: 1.8154 - accuracy: 0.8717\n",
      "Epoch 161/200\n",
      "18/18 [==============================] - 0s 944us/step - loss: 1.8152 - accuracy: 0.8717\n",
      "Epoch 162/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 1.8151 - accuracy: 0.8717\n",
      "Epoch 163/200\n",
      "18/18 [==============================] - 0s 944us/step - loss: 1.8151 - accuracy: 0.8717\n",
      "Epoch 164/200\n",
      "18/18 [==============================] - 0s 944us/step - loss: 1.8152 - accuracy: 0.8717\n",
      "Epoch 165/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 1.8152 - accuracy: 0.8717\n",
      "Epoch 166/200\n",
      "18/18 [==============================] - 0s 944us/step - loss: 1.8150 - accuracy: 0.8717\n",
      "Epoch 167/200\n",
      "18/18 [==============================] - 0s 944us/step - loss: 1.8149 - accuracy: 0.8717\n",
      "Epoch 168/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 1.8149 - accuracy: 0.8717\n",
      "Epoch 169/200\n",
      "18/18 [==============================] - 0s 944us/step - loss: 1.8148 - accuracy: 0.8717\n",
      "Epoch 170/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 1.8148 - accuracy: 0.8717\n",
      "Epoch 171/200\n",
      "18/18 [==============================] - 0s 1000us/step - loss: 1.8148 - accuracy: 0.8717\n",
      "Epoch 172/200\n",
      "18/18 [==============================] - 0s 1000us/step - loss: 1.8149 - accuracy: 0.8717\n",
      "Epoch 173/200\n",
      "18/18 [==============================] - 0s 889us/step - loss: 1.8147 - accuracy: 0.8717\n",
      "Epoch 174/200\n",
      "18/18 [==============================] - 0s 944us/step - loss: 1.8149 - accuracy: 0.8717\n",
      "Epoch 175/200\n",
      "18/18 [==============================] - 0s 944us/step - loss: 1.8147 - accuracy: 0.8717\n",
      "Epoch 176/200\n",
      "18/18 [==============================] - 0s 889us/step - loss: 1.8146 - accuracy: 0.8717\n",
      "Epoch 177/200\n",
      "18/18 [==============================] - 0s 944us/step - loss: 1.8146 - accuracy: 0.8717\n",
      "Epoch 178/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 1.8145 - accuracy: 0.8717\n",
      "Epoch 179/200\n",
      "18/18 [==============================] - 0s 944us/step - loss: 1.8145 - accuracy: 0.8717\n",
      "Epoch 180/200\n",
      "18/18 [==============================] - 0s 944us/step - loss: 1.8144 - accuracy: 0.8717\n",
      "Epoch 181/200\n",
      "18/18 [==============================] - 0s 1000us/step - loss: 1.8143 - accuracy: 0.8717\n",
      "Epoch 182/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 1.8144 - accuracy: 0.8717\n",
      "Epoch 183/200\n",
      "18/18 [==============================] - 0s 1000us/step - loss: 1.8142 - accuracy: 0.8717\n",
      "Epoch 184/200\n",
      "18/18 [==============================] - 0s 944us/step - loss: 1.8145 - accuracy: 0.8717\n",
      "Epoch 185/200\n",
      "18/18 [==============================] - 0s 889us/step - loss: 1.8143 - accuracy: 0.8717\n",
      "Epoch 186/200\n",
      "18/18 [==============================] - 0s 1000us/step - loss: 1.8146 - accuracy: 0.8717\n",
      "Epoch 187/200\n",
      "18/18 [==============================] - 0s 944us/step - loss: 1.8142 - accuracy: 0.8717\n",
      "Epoch 188/200\n",
      "18/18 [==============================] - 0s 944us/step - loss: 1.8142 - accuracy: 0.8717\n",
      "Epoch 189/200\n",
      "18/18 [==============================] - 0s 944us/step - loss: 1.8141 - accuracy: 0.8717\n",
      "Epoch 190/200\n",
      "18/18 [==============================] - 0s 1000us/step - loss: 1.8143 - accuracy: 0.8717\n",
      "Epoch 191/200\n",
      "18/18 [==============================] - 0s 889us/step - loss: 1.8140 - accuracy: 0.8717\n",
      "Epoch 192/200\n",
      "18/18 [==============================] - 0s 1000us/step - loss: 1.8140 - accuracy: 0.8717\n",
      "Epoch 193/200\n",
      "18/18 [==============================] - 0s 944us/step - loss: 1.8140 - accuracy: 0.8717\n",
      "Epoch 194/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 1.8140 - accuracy: 0.8717\n",
      "Epoch 195/200\n",
      "18/18 [==============================] - 0s 889us/step - loss: 1.8140 - accuracy: 0.8717\n",
      "Epoch 196/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 1.8141 - accuracy: 0.8717\n",
      "Epoch 197/200\n",
      "18/18 [==============================] - 0s 944us/step - loss: 1.8140 - accuracy: 0.8717\n",
      "Epoch 198/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 1.8138 - accuracy: 0.8717\n",
      "Epoch 199/200\n",
      "18/18 [==============================] - 0s 944us/step - loss: 1.8138 - accuracy: 0.8717\n",
      "Epoch 200/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 1.8140 - accuracy: 0.8717\n"
     ]
    },
    {
     "data": {
      "text/plain": "<tensorflow.python.keras.callbacks.History at 0x1cb7fe8e8e0>"
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x, y, epochs=200, verbose=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0]\n",
      "[0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 1. 1. 1. 0. 0.\n",
      " 0.]\n"
     ]
    }
   ],
   "source": [
    "print(y[:25])\n",
    "print(model.predict(x[:25]).reshape(-1))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ]
}