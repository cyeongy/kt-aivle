{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "2_1_Review _ ANN Preview I.ipynb",
   "provenance": [],
   "collapsed_sections": [
    "0xVNQT9V-Iev"
   ]
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T7kdgJptO50L",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 1일차 Review : 같은 문제 다시 풀어보기\n",
    "\n",
    "    학습은 10번으로!"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "3-aSPBeFQViu",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "from sklearn.datasets import load_boston"
   ],
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Ke9zTQOpQo3R",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "boston = load_boston()"
   ],
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\allsa\\anaconda3\\envs\\kt-aivle\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function load_boston is deprecated; `load_boston` is deprecated in 1.0 and will be removed in 1.2.\n",
      "\n",
      "    The Boston housing prices dataset has an ethical problem. You can refer to\n",
      "    the documentation of this function for further details.\n",
      "\n",
      "    The scikit-learn maintainers therefore strongly discourage the use of this\n",
      "    dataset unless the purpose of the code is to study and educate about\n",
      "    ethical issues in data science and machine learning.\n",
      "\n",
      "    In this special case, you can fetch the dataset from the original\n",
      "    source::\n",
      "\n",
      "        import pandas as pd\n",
      "        import numpy as np\n",
      "\n",
      "        data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
      "        raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
      "        data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
      "        target = raw_df.values[1::2, 2]\n",
      "\n",
      "    Alternative datasets include the California housing dataset (i.e.\n",
      "    :func:`~sklearn.datasets.fetch_california_housing`) and the Ames housing\n",
      "    dataset. You can load the datasets as follows::\n",
      "\n",
      "        from sklearn.datasets import fetch_california_housing\n",
      "        housing = fetch_california_housing()\n",
      "\n",
      "    for the California housing dataset and::\n",
      "\n",
      "        from sklearn.datasets import fetch_openml\n",
      "        housing = fetch_openml(name=\"house_prices\", as_frame=True)\n",
      "\n",
      "    for the Ames housing dataset.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "VElJM9LJQrdf",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "x = boston.data\n",
    "y = boston.target"
   ],
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "kVvDsvptQyQ_",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "x.shape, y.shape"
   ],
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "((506, 13), (506,))"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "puqIL3FCRBs6",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "#####################\n",
    "# 라이브러리 불러오기\n",
    "#####################\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "import pandas as pd\n",
    "import numpy as np\n"
   ],
   "execution_count": 10,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "broVdGpGbqrC",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "########\n",
    "# 모델링\n",
    "########\n",
    "keras.backend.clear_session()\n",
    "\n",
    "# make sequential model\n",
    "model = keras.models.Sequential()\n",
    "\n",
    "# add layers\n",
    "model.add(keras.layers.Input(shape=(13, )))\n",
    "model.add(keras.layers.Dense(1))\n",
    "\n",
    "# compile model\n",
    "model.compile(optimizer='adam', loss=keras.losses.mean_squared_error)\n"
   ],
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "4U3tZ7PvbljS",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "###########\n",
    "# 모델 학습\n",
    "###########\n",
    "model.fit(x, y, epochs=10)\n"
   ],
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "16/16 [==============================] - 0s 713us/step - loss: 2267.3506\n",
      "Epoch 2/10\n",
      "16/16 [==============================] - 0s 623us/step - loss: 1994.5404\n",
      "Epoch 3/10\n",
      "16/16 [==============================] - 0s 685us/step - loss: 1752.8436\n",
      "Epoch 4/10\n",
      "16/16 [==============================] - 0s 685us/step - loss: 1545.1062\n",
      "Epoch 5/10\n",
      "16/16 [==============================] - 0s 810us/step - loss: 1347.7313\n",
      "Epoch 6/10\n",
      "16/16 [==============================] - 0s 623us/step - loss: 1191.0999\n",
      "Epoch 7/10\n",
      "16/16 [==============================] - 0s 623us/step - loss: 1050.2058\n",
      "Epoch 8/10\n",
      "16/16 [==============================] - 0s 623us/step - loss: 921.6897\n",
      "Epoch 9/10\n",
      "16/16 [==============================] - 0s 623us/step - loss: 816.9798\n",
      "Epoch 10/10\n",
      "16/16 [==============================] - 0s 623us/step - loss: 721.5001\n"
     ]
    },
    {
     "data": {
      "text/plain": "<tensorflow.python.keras.callbacks.History at 0x28e2123d3d0>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "prSYRU-_AlYz",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "###########\n",
    "# 모델 예측\n",
    "###########\n",
    "print(y[:10])\n",
    "print(model.predict(x[:10]).reshape(-1))\n"
   ],
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[24.  21.6 34.7 33.4 36.2 28.7 22.9 27.1 16.5 18.9]\n",
      "[21.516806 21.267496 23.529177 25.901918 24.872057 23.98971  21.110353\n",
      " 17.570322 15.688065 18.035315]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0xVNQT9V-Iev",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 히든 레이어 추가하여 모델링!\n",
    "\n",
    "    히든 레이어 2개를 추가하여 다시 모델링!\n",
    "    히든 레이어 노드 수 : 32\n",
    "    히든 레이어 activation = 'relu'"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "y3PTU3m--xMa",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "########\n",
    "# 모델링\n",
    "########\n",
    "keras.backend.clear_session()\n",
    "\n",
    "# make layers\n",
    "il = Input(shape=(13,))\n",
    "h1 = Dense(32, activation='relu')(il)\n",
    "h2 = Dense(32, activation='relu')(h1)\n",
    "ol = Dense(1)(h2)\n",
    "\n",
    "# make model\n",
    "model = keras.models.Model(il, ol)\n",
    "\n",
    "# compile model\n",
    "model.compile(optimizer='adam', loss=keras.losses.mean_squared_error)\n",
    "\n"
   ],
   "execution_count": 16,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "HbvMea71-xMb",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "###########\n",
    "# 모델 학습\n",
    "###########\n",
    "model.fit(x, y, epochs=10)\n"
   ],
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "16/16 [==============================] - 0s 810us/step - loss: 13698.3115\n",
      "Epoch 2/10\n",
      "16/16 [==============================] - 0s 810us/step - loss: 622.3101\n",
      "Epoch 3/10\n",
      "16/16 [==============================] - 0s 747us/step - loss: 416.3671\n",
      "Epoch 4/10\n",
      "16/16 [==============================] - 0s 748us/step - loss: 144.4455\n",
      "Epoch 5/10\n",
      "16/16 [==============================] - 0s 685us/step - loss: 113.4645\n",
      "Epoch 6/10\n",
      "16/16 [==============================] - 0s 872us/step - loss: 103.3731\n",
      "Epoch 7/10\n",
      "16/16 [==============================] - 0s 997us/step - loss: 96.9594\n",
      "Epoch 8/10\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 89.3274\n",
      "Epoch 9/10\n",
      "16/16 [==============================] - 0s 934us/step - loss: 85.2005\n",
      "Epoch 10/10\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 81.9366\n"
     ]
    },
    {
     "data": {
      "text/plain": "<tensorflow.python.keras.callbacks.History at 0x28e58336bb0>"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "_BZMmR5--xMb",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "###########\n",
    "# 모델 예측\n",
    "###########\n",
    "print(y[:10])\n",
    "print(model.predict(x[:10]).reshape(-1))\n"
   ],
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[24.  21.6 34.7 33.4 36.2 28.7 22.9 27.1 16.5 18.9]\n",
      "[28.137798 29.321226 27.201826 26.809216 27.037361 26.946253 27.777906\n",
      " 30.577494 30.19074  29.304483]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ]
}