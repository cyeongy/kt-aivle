{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "data = fetch_california_housing()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "X = data.data\n",
    "y = data.target"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "   MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n0  8.3252      41.0  6.984127   1.023810       322.0  2.555556     37.88   \n1  8.3014      21.0  6.238137   0.971880      2401.0  2.109842     37.86   \n2  7.2574      52.0  8.288136   1.073446       496.0  2.802260     37.85   \n3  5.6431      52.0  5.817352   1.073059       558.0  2.547945     37.85   \n4  3.8462      52.0  6.281853   1.081081       565.0  2.181467     37.85   \n\n   Longitude  \n0    -122.23  \n1    -122.22  \n2    -122.24  \n3    -122.25  \n4    -122.25  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>MedInc</th>\n      <th>HouseAge</th>\n      <th>AveRooms</th>\n      <th>AveBedrms</th>\n      <th>Population</th>\n      <th>AveOccup</th>\n      <th>Latitude</th>\n      <th>Longitude</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>8.3252</td>\n      <td>41.0</td>\n      <td>6.984127</td>\n      <td>1.023810</td>\n      <td>322.0</td>\n      <td>2.555556</td>\n      <td>37.88</td>\n      <td>-122.23</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>8.3014</td>\n      <td>21.0</td>\n      <td>6.238137</td>\n      <td>0.971880</td>\n      <td>2401.0</td>\n      <td>2.109842</td>\n      <td>37.86</td>\n      <td>-122.22</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>7.2574</td>\n      <td>52.0</td>\n      <td>8.288136</td>\n      <td>1.073446</td>\n      <td>496.0</td>\n      <td>2.802260</td>\n      <td>37.85</td>\n      <td>-122.24</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>5.6431</td>\n      <td>52.0</td>\n      <td>5.817352</td>\n      <td>1.073059</td>\n      <td>558.0</td>\n      <td>2.547945</td>\n      <td>37.85</td>\n      <td>-122.25</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>3.8462</td>\n      <td>52.0</td>\n      <td>6.281853</td>\n      <td>1.081081</td>\n      <td>565.0</td>\n      <td>2.181467</td>\n      <td>37.85</td>\n      <td>-122.25</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = pd.DataFrame(data=X, columns=data.feature_names)\n",
    "X.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "   MedHouseVal\n0        4.526\n1        3.585\n2        3.521\n3        3.413\n4        3.422",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>MedHouseVal</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>4.526</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3.585</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3.521</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3.413</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>3.422</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = pd.DataFrame(data=y, columns=data.target_names)\n",
    "y.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _california_housing_dataset:\n",
      "\n",
      "California Housing dataset\n",
      "--------------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 20640\n",
      "\n",
      "    :Number of Attributes: 8 numeric, predictive attributes and the target\n",
      "\n",
      "    :Attribute Information:\n",
      "        - MedInc        median income in block group\n",
      "        - HouseAge      median house age in block group\n",
      "        - AveRooms      average number of rooms per household\n",
      "        - AveBedrms     average number of bedrooms per household\n",
      "        - Population    block group population\n",
      "        - AveOccup      average number of household members\n",
      "        - Latitude      block group latitude\n",
      "        - Longitude     block group longitude\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "This dataset was obtained from the StatLib repository.\n",
      "https://www.dcc.fc.up.pt/~ltorgo/Regression/cal_housing.html\n",
      "\n",
      "The target variable is the median house value for California districts,\n",
      "expressed in hundreds of thousands of dollars ($100,000).\n",
      "\n",
      "This dataset was derived from the 1990 U.S. census, using one row per census\n",
      "block group. A block group is the smallest geographical unit for which the U.S.\n",
      "Census Bureau publishes sample data (a block group typically has a population\n",
      "of 600 to 3,000 people).\n",
      "\n",
      "An household is a group of people residing within a home. Since the average\n",
      "number of rooms and bedrooms in this dataset are provided per household, these\n",
      "columns may take surpinsingly large values for block groups with few households\n",
      "and many empty houses, such as vacation resorts.\n",
      "\n",
      "It can be downloaded/loaded using the\n",
      ":func:`sklearn.datasets.fetch_california_housing` function.\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "    - Pace, R. Kelley and Ronald Barry, Sparse Spatial Autoregressions,\n",
      "      Statistics and Probability Letters, 33 (1997) 291-297\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(data.DESCR)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "((16512, 8), (4128, 8), (16512, 1), (4128, 1))"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, random_state=2022)\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "X_train_s = scaler.fit_transform(X_train)\n",
    "X_test_s = scaler.transform(X_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "X_train_s = pd.DataFrame(X_train_s, columns=X.columns)\n",
    "X_test_s = pd.DataFrame(X_test_s, columns=X.columns)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "             MedInc      HouseAge      AveRooms     AveBedrms    Population  \\\ncount  16512.000000  16512.000000  16512.000000  16512.000000  16512.000000   \nmean       0.233177      0.542557      0.034783      0.022586      0.039944   \nstd        0.131694      0.247020      0.017689      0.013520      0.032176   \nmin        0.000000      0.000000      0.000000      0.000000      0.000000   \n25%        0.142655      0.333333      0.027271      0.019922      0.021974   \n50%        0.209766      0.549020      0.033322      0.021192      0.032582   \n75%        0.293577      0.705882      0.039569      0.022710      0.048376   \nmax        1.000000      1.000000      1.000000      1.000000      1.000000   \n\n           AveOccup      Latitude     Longitude  \ncount  16512.000000  16512.000000  16512.000000  \nmean       0.003828      0.328671      0.476481  \nstd        0.008026      0.226990      0.199337  \nmin        0.000000      0.000000      0.000000  \n25%        0.002907      0.148188      0.253984  \n50%        0.003551      0.182303      0.583665  \n75%        0.004324      0.551173      0.631474  \nmax        1.000000      1.000000      1.000000  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>MedInc</th>\n      <th>HouseAge</th>\n      <th>AveRooms</th>\n      <th>AveBedrms</th>\n      <th>Population</th>\n      <th>AveOccup</th>\n      <th>Latitude</th>\n      <th>Longitude</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>16512.000000</td>\n      <td>16512.000000</td>\n      <td>16512.000000</td>\n      <td>16512.000000</td>\n      <td>16512.000000</td>\n      <td>16512.000000</td>\n      <td>16512.000000</td>\n      <td>16512.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>0.233177</td>\n      <td>0.542557</td>\n      <td>0.034783</td>\n      <td>0.022586</td>\n      <td>0.039944</td>\n      <td>0.003828</td>\n      <td>0.328671</td>\n      <td>0.476481</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>0.131694</td>\n      <td>0.247020</td>\n      <td>0.017689</td>\n      <td>0.013520</td>\n      <td>0.032176</td>\n      <td>0.008026</td>\n      <td>0.226990</td>\n      <td>0.199337</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>0.142655</td>\n      <td>0.333333</td>\n      <td>0.027271</td>\n      <td>0.019922</td>\n      <td>0.021974</td>\n      <td>0.002907</td>\n      <td>0.148188</td>\n      <td>0.253984</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>0.209766</td>\n      <td>0.549020</td>\n      <td>0.033322</td>\n      <td>0.021192</td>\n      <td>0.032582</td>\n      <td>0.003551</td>\n      <td>0.182303</td>\n      <td>0.583665</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>0.293577</td>\n      <td>0.705882</td>\n      <td>0.039569</td>\n      <td>0.022710</td>\n      <td>0.048376</td>\n      <td>0.004324</td>\n      <td>0.551173</td>\n      <td>0.631474</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_s.describe()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.layers import Input, Flatten, Dense\n",
    "from keras.models import *"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 128)               1152      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 34,305\n",
      "Trainable params: 34,305\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# clear session\n",
    "keras.backend.clear_session()\n",
    "\n",
    "# make Sequential model\n",
    "model = Sequential()\n",
    "\n",
    "# add layers\n",
    "model.add(Input(shape=(8,)))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "\n",
    "# compile model\n",
    "model.compile(loss=keras.losses.mean_squared_error, optimizer='adam')\n",
    "\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "es = keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                   min_delta=0,\n",
    "                                   patience=7,\n",
    "                                   verbose=1,\n",
    "                                   restore_best_weights=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "439/439 [==============================] - 1s 2ms/step - loss: 0.7792 - val_loss: 0.5563\n",
      "Epoch 2/500\n",
      "439/439 [==============================] - 1s 1ms/step - loss: 0.5180 - val_loss: 0.5649\n",
      "Epoch 3/500\n",
      "439/439 [==============================] - 0s 901us/step - loss: 0.4682 - val_loss: 0.4556\n",
      "Epoch 4/500\n",
      "439/439 [==============================] - 0s 915us/step - loss: 0.4382 - val_loss: 0.4326\n",
      "Epoch 5/500\n",
      "439/439 [==============================] - 0s 940us/step - loss: 0.4269 - val_loss: 0.4220\n",
      "Epoch 6/500\n",
      "439/439 [==============================] - 0s 960us/step - loss: 0.4031 - val_loss: 0.4426\n",
      "Epoch 7/500\n",
      "439/439 [==============================] - 0s 951us/step - loss: 0.3955 - val_loss: 0.4017\n",
      "Epoch 8/500\n",
      "439/439 [==============================] - 0s 908us/step - loss: 0.3788 - val_loss: 0.4238\n",
      "Epoch 9/500\n",
      "439/439 [==============================] - 0s 901us/step - loss: 0.3763 - val_loss: 0.3877\n",
      "Epoch 10/500\n",
      "439/439 [==============================] - 0s 906us/step - loss: 0.3689 - val_loss: 0.3909\n",
      "Epoch 11/500\n",
      "439/439 [==============================] - 0s 963us/step - loss: 0.3611 - val_loss: 0.4326\n",
      "Epoch 12/500\n",
      "439/439 [==============================] - 0s 951us/step - loss: 0.3649 - val_loss: 0.3442\n",
      "Epoch 13/500\n",
      "439/439 [==============================] - 0s 940us/step - loss: 0.3564 - val_loss: 0.3499\n",
      "Epoch 14/500\n",
      "439/439 [==============================] - 0s 938us/step - loss: 0.3507 - val_loss: 0.3477\n",
      "Epoch 15/500\n",
      "439/439 [==============================] - 0s 1ms/step - loss: 0.3369 - val_loss: 0.3516\n",
      "Epoch 16/500\n",
      "439/439 [==============================] - 0s 976us/step - loss: 0.3425 - val_loss: 0.3317\n",
      "Epoch 17/500\n",
      "439/439 [==============================] - 0s 1ms/step - loss: 0.3329 - val_loss: 0.3714\n",
      "Epoch 18/500\n",
      "439/439 [==============================] - 0s 1ms/step - loss: 0.3233 - val_loss: 0.4079\n",
      "Epoch 19/500\n",
      "439/439 [==============================] - 0s 1ms/step - loss: 0.3285 - val_loss: 0.3221\n",
      "Epoch 20/500\n",
      "439/439 [==============================] - 0s 1ms/step - loss: 0.3340 - val_loss: 0.3937\n",
      "Epoch 21/500\n",
      "439/439 [==============================] - 0s 1ms/step - loss: 0.3237 - val_loss: 0.3422\n",
      "Epoch 22/500\n",
      "439/439 [==============================] - 0s 1ms/step - loss: 0.3186 - val_loss: 0.3177\n",
      "Epoch 23/500\n",
      "439/439 [==============================] - 0s 1ms/step - loss: 0.3168 - val_loss: 0.3174\n",
      "Epoch 24/500\n",
      "439/439 [==============================] - 0s 1ms/step - loss: 0.3159 - val_loss: 0.3294\n",
      "Epoch 25/500\n",
      "439/439 [==============================] - 1s 1ms/step - loss: 0.3219 - val_loss: 0.3165\n",
      "Epoch 26/500\n",
      "439/439 [==============================] - 1s 1ms/step - loss: 0.3140 - val_loss: 0.3215\n",
      "Epoch 27/500\n",
      "439/439 [==============================] - 0s 1ms/step - loss: 0.3153 - val_loss: 0.3474\n",
      "Epoch 28/500\n",
      "439/439 [==============================] - 0s 1ms/step - loss: 0.3067 - val_loss: 0.3060\n",
      "Epoch 29/500\n",
      "439/439 [==============================] - 0s 913us/step - loss: 0.3082 - val_loss: 0.3150\n",
      "Epoch 30/500\n",
      "439/439 [==============================] - 0s 917us/step - loss: 0.3029 - val_loss: 0.2972\n",
      "Epoch 31/500\n",
      "439/439 [==============================] - 0s 885us/step - loss: 0.2994 - val_loss: 0.3176\n",
      "Epoch 32/500\n",
      "439/439 [==============================] - 0s 888us/step - loss: 0.3034 - val_loss: 0.3225\n",
      "Epoch 33/500\n",
      "439/439 [==============================] - 0s 938us/step - loss: 0.2964 - val_loss: 0.3122\n",
      "Epoch 34/500\n",
      "439/439 [==============================] - 0s 942us/step - loss: 0.2986 - val_loss: 0.3001\n",
      "Epoch 35/500\n",
      "439/439 [==============================] - 0s 913us/step - loss: 0.2908 - val_loss: 0.2964\n",
      "Epoch 36/500\n",
      "439/439 [==============================] - 0s 944us/step - loss: 0.2911 - val_loss: 0.3065\n",
      "Epoch 37/500\n",
      "439/439 [==============================] - 0s 919us/step - loss: 0.2895 - val_loss: 0.3237\n",
      "Epoch 38/500\n",
      "439/439 [==============================] - 0s 949us/step - loss: 0.2910 - val_loss: 0.2914\n",
      "Epoch 39/500\n",
      "439/439 [==============================] - 0s 994us/step - loss: 0.2905 - val_loss: 0.3142\n",
      "Epoch 40/500\n",
      "439/439 [==============================] - 0s 965us/step - loss: 0.2881 - val_loss: 0.3047\n",
      "Epoch 41/500\n",
      "439/439 [==============================] - 0s 997us/step - loss: 0.2849 - val_loss: 0.2894\n",
      "Epoch 42/500\n",
      "439/439 [==============================] - 0s 1ms/step - loss: 0.2888 - val_loss: 0.2872\n",
      "Epoch 43/500\n",
      "439/439 [==============================] - 0s 1ms/step - loss: 0.2878 - val_loss: 0.2843\n",
      "Epoch 44/500\n",
      "439/439 [==============================] - 0s 1ms/step - loss: 0.2834 - val_loss: 0.3240\n",
      "Epoch 45/500\n",
      "439/439 [==============================] - 0s 1ms/step - loss: 0.2814 - val_loss: 0.2973\n",
      "Epoch 46/500\n",
      "439/439 [==============================] - 0s 1ms/step - loss: 0.2784 - val_loss: 0.2804\n",
      "Epoch 47/500\n",
      "439/439 [==============================] - 0s 1ms/step - loss: 0.2778 - val_loss: 0.2824\n",
      "Epoch 48/500\n",
      "439/439 [==============================] - 0s 985us/step - loss: 0.2761 - val_loss: 0.2976\n",
      "Epoch 49/500\n",
      "439/439 [==============================] - 0s 990us/step - loss: 0.2753 - val_loss: 0.3195\n",
      "Epoch 50/500\n",
      "439/439 [==============================] - 0s 1ms/step - loss: 0.2826 - val_loss: 0.3073\n",
      "Epoch 51/500\n",
      "439/439 [==============================] - 0s 1ms/step - loss: 0.2750 - val_loss: 0.3124\n",
      "Epoch 52/500\n",
      "439/439 [==============================] - 0s 1ms/step - loss: 0.2781 - val_loss: 0.2777\n",
      "Epoch 53/500\n",
      "439/439 [==============================] - 0s 1ms/step - loss: 0.2718 - val_loss: 0.3015\n",
      "Epoch 54/500\n",
      "439/439 [==============================] - 0s 1ms/step - loss: 0.2707 - val_loss: 0.2864\n",
      "Epoch 55/500\n",
      "439/439 [==============================] - 1s 1ms/step - loss: 0.2736 - val_loss: 0.2848\n",
      "Epoch 56/500\n",
      "439/439 [==============================] - 0s 1ms/step - loss: 0.2693 - val_loss: 0.2880\n",
      "Epoch 57/500\n",
      "439/439 [==============================] - 0s 1ms/step - loss: 0.2688 - val_loss: 0.2743\n",
      "Epoch 58/500\n",
      "439/439 [==============================] - 1s 1ms/step - loss: 0.2619 - val_loss: 0.2799\n",
      "Epoch 59/500\n",
      "439/439 [==============================] - 0s 1ms/step - loss: 0.2638 - val_loss: 0.2872\n",
      "Epoch 60/500\n",
      "439/439 [==============================] - 0s 1ms/step - loss: 0.2632 - val_loss: 0.2967\n",
      "Epoch 61/500\n",
      "439/439 [==============================] - 0s 1ms/step - loss: 0.2628 - val_loss: 0.2774\n",
      "Epoch 62/500\n",
      "439/439 [==============================] - 0s 1ms/step - loss: 0.2593 - val_loss: 0.2902\n",
      "Epoch 63/500\n",
      "439/439 [==============================] - 0s 1ms/step - loss: 0.2587 - val_loss: 0.2820\n",
      "Epoch 64/500\n",
      "439/439 [==============================] - 0s 1ms/step - loss: 0.2605 - val_loss: 0.2703\n",
      "Epoch 65/500\n",
      "439/439 [==============================] - 0s 1ms/step - loss: 0.2564 - val_loss: 0.3083\n",
      "Epoch 66/500\n",
      "439/439 [==============================] - 0s 1ms/step - loss: 0.2628 - val_loss: 0.2811\n",
      "Epoch 67/500\n",
      "439/439 [==============================] - 0s 1ms/step - loss: 0.2581 - val_loss: 0.2867\n",
      "Epoch 68/500\n",
      "439/439 [==============================] - 0s 1ms/step - loss: 0.2589 - val_loss: 0.2687\n",
      "Epoch 69/500\n",
      "439/439 [==============================] - 0s 1ms/step - loss: 0.2600 - val_loss: 0.2813\n",
      "Epoch 70/500\n",
      "439/439 [==============================] - 0s 1ms/step - loss: 0.2503 - val_loss: 0.2734\n",
      "Epoch 71/500\n",
      "439/439 [==============================] - 0s 1ms/step - loss: 0.2561 - val_loss: 0.2852\n",
      "Epoch 72/500\n",
      "439/439 [==============================] - 0s 1ms/step - loss: 0.2504 - val_loss: 0.2795\n",
      "Epoch 73/500\n",
      "439/439 [==============================] - 1s 1ms/step - loss: 0.2487 - val_loss: 0.2779\n",
      "Epoch 74/500\n",
      "439/439 [==============================] - 0s 1ms/step - loss: 0.2532 - val_loss: 0.3009\n",
      "Epoch 75/500\n",
      "397/439 [==========================>...] - ETA: 0s - loss: 0.2522Restoring model weights from the end of the best epoch.\n",
      "439/439 [==============================] - 0s 997us/step - loss: 0.2543 - val_loss: 0.2763\n",
      "Epoch 00075: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": "<tensorflow.python.keras.callbacks.History at 0x184013b7af0>"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_s, y_train, epochs=500, verbose=1,\n",
    "          validation_split=.15,\n",
    "          callbacks=[es])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Wine"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_wine\n",
    "\n",
    "data = load_wine()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "X = data.data\n",
    "y = data.target"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "((151, 13), (27, 13), (151,), (27,))"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.15, random_state=2022)\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "cat_n = len(np.unique(y_train))\n",
    "\n",
    "y_train = keras.utils.to_categorical(y_train, cat_n)\n",
    "y_test = keras.utils.to_categorical(y_test, cat_n)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "   alcohol  malic_acid   ash  alcalinity_of_ash  magnesium  total_phenols  \\\n0    14.23        1.71  2.43               15.6      127.0           2.80   \n1    13.20        1.78  2.14               11.2      100.0           2.65   \n2    13.16        2.36  2.67               18.6      101.0           2.80   \n3    14.37        1.95  2.50               16.8      113.0           3.85   \n4    13.24        2.59  2.87               21.0      118.0           2.80   \n\n   flavanoids  nonflavanoid_phenols  proanthocyanins  color_intensity   hue  \\\n0        3.06                  0.28             2.29             5.64  1.04   \n1        2.76                  0.26             1.28             4.38  1.05   \n2        3.24                  0.30             2.81             5.68  1.03   \n3        3.49                  0.24             2.18             7.80  0.86   \n4        2.69                  0.39             1.82             4.32  1.04   \n\n   od280/od315_of_diluted_wines  proline  \n0                          3.92   1065.0  \n1                          3.40   1050.0  \n2                          3.17   1185.0  \n3                          3.45   1480.0  \n4                          2.93    735.0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>alcohol</th>\n      <th>malic_acid</th>\n      <th>ash</th>\n      <th>alcalinity_of_ash</th>\n      <th>magnesium</th>\n      <th>total_phenols</th>\n      <th>flavanoids</th>\n      <th>nonflavanoid_phenols</th>\n      <th>proanthocyanins</th>\n      <th>color_intensity</th>\n      <th>hue</th>\n      <th>od280/od315_of_diluted_wines</th>\n      <th>proline</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>14.23</td>\n      <td>1.71</td>\n      <td>2.43</td>\n      <td>15.6</td>\n      <td>127.0</td>\n      <td>2.80</td>\n      <td>3.06</td>\n      <td>0.28</td>\n      <td>2.29</td>\n      <td>5.64</td>\n      <td>1.04</td>\n      <td>3.92</td>\n      <td>1065.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>13.20</td>\n      <td>1.78</td>\n      <td>2.14</td>\n      <td>11.2</td>\n      <td>100.0</td>\n      <td>2.65</td>\n      <td>2.76</td>\n      <td>0.26</td>\n      <td>1.28</td>\n      <td>4.38</td>\n      <td>1.05</td>\n      <td>3.40</td>\n      <td>1050.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>13.16</td>\n      <td>2.36</td>\n      <td>2.67</td>\n      <td>18.6</td>\n      <td>101.0</td>\n      <td>2.80</td>\n      <td>3.24</td>\n      <td>0.30</td>\n      <td>2.81</td>\n      <td>5.68</td>\n      <td>1.03</td>\n      <td>3.17</td>\n      <td>1185.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>14.37</td>\n      <td>1.95</td>\n      <td>2.50</td>\n      <td>16.8</td>\n      <td>113.0</td>\n      <td>3.85</td>\n      <td>3.49</td>\n      <td>0.24</td>\n      <td>2.18</td>\n      <td>7.80</td>\n      <td>0.86</td>\n      <td>3.45</td>\n      <td>1480.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>13.24</td>\n      <td>2.59</td>\n      <td>2.87</td>\n      <td>21.0</td>\n      <td>118.0</td>\n      <td>2.80</td>\n      <td>2.69</td>\n      <td>0.39</td>\n      <td>1.82</td>\n      <td>4.32</td>\n      <td>1.04</td>\n      <td>2.93</td>\n      <td>735.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = pd.DataFrame(data=X, columns=data.feature_names)\n",
    "X.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "data": {
      "text/plain": "   class_0  class_1  class_2\n0      1.0      0.0      0.0\n1      0.0      0.0      1.0\n2      1.0      0.0      0.0\n3      0.0      1.0      0.0\n4      0.0      0.0      1.0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>class_0</th>\n      <th>class_1</th>\n      <th>class_2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = pd.DataFrame(data=y_train, columns=data.target_names)\n",
    "y_train.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _wine_dataset:\n",
      "\n",
      "Wine recognition dataset\n",
      "------------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 178 (50 in each of three classes)\n",
      "    :Number of Attributes: 13 numeric, predictive attributes and the class\n",
      "    :Attribute Information:\n",
      " \t\t- Alcohol\n",
      " \t\t- Malic acid\n",
      " \t\t- Ash\n",
      "\t\t- Alcalinity of ash  \n",
      " \t\t- Magnesium\n",
      "\t\t- Total phenols\n",
      " \t\t- Flavanoids\n",
      " \t\t- Nonflavanoid phenols\n",
      " \t\t- Proanthocyanins\n",
      "\t\t- Color intensity\n",
      " \t\t- Hue\n",
      " \t\t- OD280/OD315 of diluted wines\n",
      " \t\t- Proline\n",
      "\n",
      "    - class:\n",
      "            - class_0\n",
      "            - class_1\n",
      "            - class_2\n",
      "\t\t\n",
      "    :Summary Statistics:\n",
      "    \n",
      "    ============================= ==== ===== ======= =====\n",
      "                                   Min   Max   Mean     SD\n",
      "    ============================= ==== ===== ======= =====\n",
      "    Alcohol:                      11.0  14.8    13.0   0.8\n",
      "    Malic Acid:                   0.74  5.80    2.34  1.12\n",
      "    Ash:                          1.36  3.23    2.36  0.27\n",
      "    Alcalinity of Ash:            10.6  30.0    19.5   3.3\n",
      "    Magnesium:                    70.0 162.0    99.7  14.3\n",
      "    Total Phenols:                0.98  3.88    2.29  0.63\n",
      "    Flavanoids:                   0.34  5.08    2.03  1.00\n",
      "    Nonflavanoid Phenols:         0.13  0.66    0.36  0.12\n",
      "    Proanthocyanins:              0.41  3.58    1.59  0.57\n",
      "    Colour Intensity:              1.3  13.0     5.1   2.3\n",
      "    Hue:                          0.48  1.71    0.96  0.23\n",
      "    OD280/OD315 of diluted wines: 1.27  4.00    2.61  0.71\n",
      "    Proline:                       278  1680     746   315\n",
      "    ============================= ==== ===== ======= =====\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "    :Class Distribution: class_0 (59), class_1 (71), class_2 (48)\n",
      "    :Creator: R.A. Fisher\n",
      "    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\n",
      "    :Date: July, 1988\n",
      "\n",
      "This is a copy of UCI ML Wine recognition datasets.\n",
      "https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data\n",
      "\n",
      "The data is the results of a chemical analysis of wines grown in the same\n",
      "region in Italy by three different cultivators. There are thirteen different\n",
      "measurements taken for different constituents found in the three types of\n",
      "wine.\n",
      "\n",
      "Original Owners: \n",
      "\n",
      "Forina, M. et al, PARVUS - \n",
      "An Extendible Package for Data Exploration, Classification and Correlation. \n",
      "Institute of Pharmaceutical and Food Analysis and Technologies,\n",
      "Via Brigata Salerno, 16147 Genoa, Italy.\n",
      "\n",
      "Citation:\n",
      "\n",
      "Lichman, M. (2013). UCI Machine Learning Repository\n",
      "[https://archive.ics.uci.edu/ml]. Irvine, CA: University of California,\n",
      "School of Information and Computer Science. \n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "  (1) S. Aeberhard, D. Coomans and O. de Vel, \n",
      "  Comparison of Classifiers in High Dimensional Settings, \n",
      "  Tech. Rep. no. 92-02, (1992), Dept. of Computer Science and Dept. of  \n",
      "  Mathematics and Statistics, James Cook University of North Queensland. \n",
      "  (Also submitted to Technometrics). \n",
      "\n",
      "  The data was used with many others for comparing various \n",
      "  classifiers. The classes are separable, though only RDA \n",
      "  has achieved 100% correct classification. \n",
      "  (RDA : 100%, QDA 99.4%, LDA 98.9%, 1NN 96.1% (z-transformed data)) \n",
      "  (All results using the leave-one-out technique) \n",
      "\n",
      "  (2) S. Aeberhard, D. Coomans and O. de Vel, \n",
      "  \"THE CLASSIFICATION PERFORMANCE OF RDA\" \n",
      "  Tech. Rep. no. 92-01, (1992), Dept. of Computer Science and Dept. of \n",
      "  Mathematics and Statistics, James Cook University of North Queensland. \n",
      "  (Also submitted to Journal of Chemometrics).\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(data.DESCR)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "X_train_s = scaler.fit_transform(X_train)\n",
    "X_test_s = scaler.transform(X_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "es = keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                   min_delta=0,\n",
    "                                   patience=5,\n",
    "                                   restore_best_weights=True,\n",
    "                                   verbose=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 13)]              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 3)                 42        \n",
      "=================================================================\n",
      "Total params: 42\n",
      "Trainable params: 42\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# clear session\n",
    "keras.backend.clear_session()\n",
    "\n",
    "il = Input(shape=X_train_s.shape[1:])\n",
    "ol = Dense(3, activation='softmax')(il)\n",
    "\n",
    "reg_model = Model(il, ol)\n",
    "\n",
    "reg_model.compile(loss=keras.losses.categorical_crossentropy, optimizer='adam', metrics=['mse'])\n",
    "\n",
    "reg_model.summary()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1.3057 - mse: 0.2675 - val_loss: 1.2810 - val_mse: 0.2639\n",
      "Epoch 2/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1.2971 - mse: 0.2658 - val_loss: 1.2720 - val_mse: 0.2620\n",
      "Epoch 3/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.2888 - mse: 0.2641 - val_loss: 1.2639 - val_mse: 0.2602\n",
      "Epoch 4/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1.2812 - mse: 0.2625 - val_loss: 1.2562 - val_mse: 0.2586\n",
      "Epoch 5/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1.2734 - mse: 0.2610 - val_loss: 1.2478 - val_mse: 0.2567\n",
      "Epoch 6/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1.2661 - mse: 0.2595 - val_loss: 1.2413 - val_mse: 0.2554\n",
      "Epoch 7/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1.2597 - mse: 0.2582 - val_loss: 1.2355 - val_mse: 0.2541\n",
      "Epoch 8/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1.2532 - mse: 0.2569 - val_loss: 1.2314 - val_mse: 0.2532\n",
      "Epoch 9/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.2468 - mse: 0.2556 - val_loss: 1.2250 - val_mse: 0.2519\n",
      "Epoch 10/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1.2409 - mse: 0.2545 - val_loss: 1.2187 - val_mse: 0.2506\n",
      "Epoch 11/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.2353 - mse: 0.2533 - val_loss: 1.2128 - val_mse: 0.2493\n",
      "Epoch 12/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.2293 - mse: 0.2521 - val_loss: 1.2081 - val_mse: 0.2484\n",
      "Epoch 13/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1.2234 - mse: 0.2509 - val_loss: 1.2044 - val_mse: 0.2476\n",
      "Epoch 14/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.2174 - mse: 0.2497 - val_loss: 1.1999 - val_mse: 0.2466\n",
      "Epoch 15/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.2119 - mse: 0.2486 - val_loss: 1.1953 - val_mse: 0.2457\n",
      "Epoch 16/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1.2061 - mse: 0.2474 - val_loss: 1.1896 - val_mse: 0.2445\n",
      "Epoch 17/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.2006 - mse: 0.2463 - val_loss: 1.1840 - val_mse: 0.2433\n",
      "Epoch 18/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.1952 - mse: 0.2452 - val_loss: 1.1774 - val_mse: 0.2420\n",
      "Epoch 19/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.1898 - mse: 0.2441 - val_loss: 1.1721 - val_mse: 0.2409\n",
      "Epoch 20/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1.1844 - mse: 0.2430 - val_loss: 1.1669 - val_mse: 0.2398\n",
      "Epoch 21/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.1789 - mse: 0.2419 - val_loss: 1.1619 - val_mse: 0.2387\n",
      "Epoch 22/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.1738 - mse: 0.2409 - val_loss: 1.1575 - val_mse: 0.2378\n",
      "Epoch 23/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.1683 - mse: 0.2397 - val_loss: 1.1516 - val_mse: 0.2366\n",
      "Epoch 24/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1.1629 - mse: 0.2386 - val_loss: 1.1460 - val_mse: 0.2354\n",
      "Epoch 25/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.1576 - mse: 0.2375 - val_loss: 1.1414 - val_mse: 0.2345\n",
      "Epoch 26/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1.1524 - mse: 0.2365 - val_loss: 1.1376 - val_mse: 0.2336\n",
      "Epoch 27/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.1471 - mse: 0.2353 - val_loss: 1.1339 - val_mse: 0.2328\n",
      "Epoch 28/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.1419 - mse: 0.2343 - val_loss: 1.1295 - val_mse: 0.2319\n",
      "Epoch 29/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.1367 - mse: 0.2331 - val_loss: 1.1245 - val_mse: 0.2308\n",
      "Epoch 30/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.1315 - mse: 0.2320 - val_loss: 1.1177 - val_mse: 0.2293\n",
      "Epoch 31/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.1265 - mse: 0.2310 - val_loss: 1.1110 - val_mse: 0.2279\n",
      "Epoch 32/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.1214 - mse: 0.2299 - val_loss: 1.1051 - val_mse: 0.2266\n",
      "Epoch 33/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1.1165 - mse: 0.2289 - val_loss: 1.0982 - val_mse: 0.2251\n",
      "Epoch 34/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1.1117 - mse: 0.2279 - val_loss: 1.0912 - val_mse: 0.2236\n",
      "Epoch 35/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.1068 - mse: 0.2269 - val_loss: 1.0860 - val_mse: 0.2225\n",
      "Epoch 36/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.1019 - mse: 0.2258 - val_loss: 1.0805 - val_mse: 0.2213\n",
      "Epoch 37/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1.0974 - mse: 0.2249 - val_loss: 1.0745 - val_mse: 0.2201\n",
      "Epoch 38/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.0924 - mse: 0.2238 - val_loss: 1.0705 - val_mse: 0.2192\n",
      "Epoch 39/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1.0874 - mse: 0.2228 - val_loss: 1.0664 - val_mse: 0.2183\n",
      "Epoch 40/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.0827 - mse: 0.2218 - val_loss: 1.0627 - val_mse: 0.2175\n",
      "Epoch 41/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.0778 - mse: 0.2207 - val_loss: 1.0580 - val_mse: 0.2164\n",
      "Epoch 42/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1.0731 - mse: 0.2196 - val_loss: 1.0540 - val_mse: 0.2155\n",
      "Epoch 43/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.0684 - mse: 0.2186 - val_loss: 1.0483 - val_mse: 0.2142\n",
      "Epoch 44/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.0637 - mse: 0.2176 - val_loss: 1.0443 - val_mse: 0.2133\n",
      "Epoch 45/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.0591 - mse: 0.2166 - val_loss: 1.0407 - val_mse: 0.2125\n",
      "Epoch 46/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.0545 - mse: 0.2156 - val_loss: 1.0375 - val_mse: 0.2118\n",
      "Epoch 47/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1.0499 - mse: 0.2146 - val_loss: 1.0337 - val_mse: 0.2110\n",
      "Epoch 48/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.0452 - mse: 0.2136 - val_loss: 1.0306 - val_mse: 0.2103\n",
      "Epoch 49/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.0408 - mse: 0.2126 - val_loss: 1.0279 - val_mse: 0.2097\n",
      "Epoch 50/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.0364 - mse: 0.2116 - val_loss: 1.0248 - val_mse: 0.2090\n",
      "Epoch 51/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1.0318 - mse: 0.2106 - val_loss: 1.0211 - val_mse: 0.2081\n",
      "Epoch 52/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.0276 - mse: 0.2097 - val_loss: 1.0176 - val_mse: 0.2073\n",
      "Epoch 53/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.0229 - mse: 0.2086 - val_loss: 1.0124 - val_mse: 0.2062\n",
      "Epoch 54/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.0186 - mse: 0.2077 - val_loss: 1.0062 - val_mse: 0.2048\n",
      "Epoch 55/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1.0141 - mse: 0.2067 - val_loss: 1.0012 - val_mse: 0.2036\n",
      "Epoch 56/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.0097 - mse: 0.2056 - val_loss: 0.9963 - val_mse: 0.2024\n",
      "Epoch 57/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1.0053 - mse: 0.2046 - val_loss: 0.9919 - val_mse: 0.2014\n",
      "Epoch 58/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1.0010 - mse: 0.2036 - val_loss: 0.9875 - val_mse: 0.2003\n",
      "Epoch 59/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.9968 - mse: 0.2027 - val_loss: 0.9833 - val_mse: 0.1994\n",
      "Epoch 60/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.9925 - mse: 0.2017 - val_loss: 0.9802 - val_mse: 0.1986\n",
      "Epoch 61/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.9882 - mse: 0.2007 - val_loss: 0.9772 - val_mse: 0.1979\n",
      "Epoch 62/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.9841 - mse: 0.1998 - val_loss: 0.9735 - val_mse: 0.1971\n",
      "Epoch 63/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.9802 - mse: 0.1989 - val_loss: 0.9701 - val_mse: 0.1963\n",
      "Epoch 64/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.9759 - mse: 0.1979 - val_loss: 0.9659 - val_mse: 0.1953\n",
      "Epoch 65/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.9715 - mse: 0.1969 - val_loss: 0.9635 - val_mse: 0.1947\n",
      "Epoch 66/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.9675 - mse: 0.1960 - val_loss: 0.9607 - val_mse: 0.1941\n",
      "Epoch 67/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.9635 - mse: 0.1951 - val_loss: 0.9576 - val_mse: 0.1933\n",
      "Epoch 68/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.9594 - mse: 0.1941 - val_loss: 0.9535 - val_mse: 0.1923\n",
      "Epoch 69/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.9554 - mse: 0.1931 - val_loss: 0.9494 - val_mse: 0.1913\n",
      "Epoch 70/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.9514 - mse: 0.1922 - val_loss: 0.9448 - val_mse: 0.1902\n",
      "Epoch 71/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.9472 - mse: 0.1912 - val_loss: 0.9404 - val_mse: 0.1892\n",
      "Epoch 72/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.9432 - mse: 0.1903 - val_loss: 0.9365 - val_mse: 0.1883\n",
      "Epoch 73/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.9393 - mse: 0.1894 - val_loss: 0.9326 - val_mse: 0.1873\n",
      "Epoch 74/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.9352 - mse: 0.1884 - val_loss: 0.9277 - val_mse: 0.1862\n",
      "Epoch 75/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.9313 - mse: 0.1875 - val_loss: 0.9225 - val_mse: 0.1850\n",
      "Epoch 76/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.9273 - mse: 0.1866 - val_loss: 0.9180 - val_mse: 0.1839\n",
      "Epoch 77/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.9234 - mse: 0.1857 - val_loss: 0.9132 - val_mse: 0.1828\n",
      "Epoch 78/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.9196 - mse: 0.1848 - val_loss: 0.9091 - val_mse: 0.1818\n",
      "Epoch 79/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.9156 - mse: 0.1838 - val_loss: 0.9054 - val_mse: 0.1809\n",
      "Epoch 80/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.9118 - mse: 0.1829 - val_loss: 0.9007 - val_mse: 0.1797\n",
      "Epoch 81/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.9081 - mse: 0.1820 - val_loss: 0.8964 - val_mse: 0.1787\n",
      "Epoch 82/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.9042 - mse: 0.1811 - val_loss: 0.8918 - val_mse: 0.1776\n",
      "Epoch 83/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.9007 - mse: 0.1803 - val_loss: 0.8876 - val_mse: 0.1766\n",
      "Epoch 84/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.8970 - mse: 0.1794 - val_loss: 0.8844 - val_mse: 0.1758\n",
      "Epoch 85/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.8934 - mse: 0.1786 - val_loss: 0.8812 - val_mse: 0.1751\n",
      "Epoch 86/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.8896 - mse: 0.1777 - val_loss: 0.8768 - val_mse: 0.1740\n",
      "Epoch 87/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.8860 - mse: 0.1768 - val_loss: 0.8719 - val_mse: 0.1728\n",
      "Epoch 88/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.8827 - mse: 0.1760 - val_loss: 0.8669 - val_mse: 0.1716\n",
      "Epoch 89/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.8791 - mse: 0.1752 - val_loss: 0.8623 - val_mse: 0.1706\n",
      "Epoch 90/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.8756 - mse: 0.1744 - val_loss: 0.8575 - val_mse: 0.1695\n",
      "Epoch 91/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.8721 - mse: 0.1736 - val_loss: 0.8535 - val_mse: 0.1686\n",
      "Epoch 92/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.8686 - mse: 0.1728 - val_loss: 0.8494 - val_mse: 0.1676\n",
      "Epoch 93/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.8651 - mse: 0.1720 - val_loss: 0.8453 - val_mse: 0.1666\n",
      "Epoch 94/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.8618 - mse: 0.1712 - val_loss: 0.8427 - val_mse: 0.1660\n",
      "Epoch 95/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.8579 - mse: 0.1703 - val_loss: 0.8392 - val_mse: 0.1651\n",
      "Epoch 96/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.8544 - mse: 0.1694 - val_loss: 0.8361 - val_mse: 0.1643\n",
      "Epoch 97/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.8510 - mse: 0.1686 - val_loss: 0.8340 - val_mse: 0.1638\n",
      "Epoch 98/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.8475 - mse: 0.1677 - val_loss: 0.8311 - val_mse: 0.1631\n",
      "Epoch 99/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.8440 - mse: 0.1669 - val_loss: 0.8274 - val_mse: 0.1622\n",
      "Epoch 100/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.8407 - mse: 0.1661 - val_loss: 0.8237 - val_mse: 0.1613\n"
     ]
    },
    {
     "data": {
      "text/plain": "<tensorflow.python.keras.callbacks.History at 0x187104ead30>"
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_model.fit(X_train_s, y_train, epochs=100, validation_split=.1,\n",
    "              callbacks=[es],\n",
    "              verbose=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 997us/step - loss: 0.8556 - mse: 0.1695\n"
     ]
    },
    {
     "data": {
      "text/plain": "[0.8556076288223267, 0.16945450007915497]"
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_model.evaluate(X_test_s, y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 13)]              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               7168      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3)                 771       \n",
      "=================================================================\n",
      "Total params: 139,267\n",
      "Trainable params: 139,267\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# clear session\n",
    "keras.backend.clear_session()\n",
    "\n",
    "il = Input(shape=X_train_s.shape[1:])\n",
    "h1 = Dense(512, activation='relu')(il)\n",
    "h2 = Dense(256, activation='relu')(h1)\n",
    "ol = Dense(3, activation='softmax')(h2)\n",
    "\n",
    "model = Model(il, ol)\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy, optimizer='adam', metrics=['mse'])\n",
    "\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1.0147 - mse: 0.2033 - val_loss: 0.8179 - val_mse: 0.1576\n",
      "Epoch 2/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.7689 - mse: 0.1460 - val_loss: 0.5890 - val_mse: 0.1013\n",
      "Epoch 3/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.5592 - mse: 0.0963 - val_loss: 0.3840 - val_mse: 0.0554\n",
      "Epoch 4/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.4037 - mse: 0.0651 - val_loss: 0.2606 - val_mse: 0.0340\n",
      "Epoch 5/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2824 - mse: 0.0423 - val_loss: 0.1971 - val_mse: 0.0260\n",
      "Epoch 6/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.2138 - mse: 0.0329 - val_loss: 0.1083 - val_mse: 0.0098\n",
      "Epoch 7/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.1765 - mse: 0.0289 - val_loss: 0.0667 - val_mse: 0.0044\n",
      "Epoch 8/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.1274 - mse: 0.0183 - val_loss: 0.1077 - val_mse: 0.0165\n",
      "Epoch 9/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.1299 - mse: 0.0200 - val_loss: 0.0420 - val_mse: 0.0026\n",
      "Epoch 10/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0970 - mse: 0.0147 - val_loss: 0.0338 - val_mse: 0.0021\n",
      "Epoch 11/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0822 - mse: 0.0121 - val_loss: 0.0460 - val_mse: 0.0052\n",
      "Epoch 12/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0780 - mse: 0.0113 - val_loss: 0.0274 - val_mse: 0.0017\n",
      "Epoch 13/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0655 - mse: 0.0085 - val_loss: 0.0173 - val_mse: 4.5755e-04\n",
      "Epoch 14/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0593 - mse: 0.0083 - val_loss: 0.0300 - val_mse: 0.0030\n",
      "Epoch 15/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0517 - mse: 0.0070 - val_loss: 0.0356 - val_mse: 0.0044\n",
      "Epoch 16/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0487 - mse: 0.0063 - val_loss: 0.0167 - val_mse: 8.1458e-04\n",
      "Epoch 17/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0430 - mse: 0.0046 - val_loss: 0.0122 - val_mse: 2.8516e-04\n",
      "Epoch 18/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0387 - mse: 0.0039 - val_loss: 0.0175 - val_mse: 0.0011\n",
      "Epoch 19/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0338 - mse: 0.0033 - val_loss: 0.0182 - val_mse: 0.0014\n",
      "Epoch 20/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0294 - mse: 0.0027 - val_loss: 0.0094 - val_mse: 2.7839e-04\n",
      "Epoch 21/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0282 - mse: 0.0027 - val_loss: 0.0098 - val_mse: 3.7646e-04\n",
      "Epoch 22/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0248 - mse: 0.0021 - val_loss: 0.0094 - val_mse: 3.7087e-04\n",
      "Epoch 23/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0224 - mse: 0.0017 - val_loss: 0.0085 - val_mse: 3.0034e-04\n",
      "Epoch 24/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0211 - mse: 0.0016 - val_loss: 0.0091 - val_mse: 3.8809e-04\n",
      "Epoch 25/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0197 - mse: 0.0014 - val_loss: 0.0102 - val_mse: 5.1660e-04\n",
      "Epoch 26/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0184 - mse: 0.0012 - val_loss: 0.0060 - val_mse: 1.3835e-04\n",
      "Epoch 27/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0164 - mse: 9.4511e-04 - val_loss: 0.0066 - val_mse: 2.0818e-04\n",
      "Epoch 28/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0147 - mse: 7.7476e-04 - val_loss: 0.0073 - val_mse: 2.8443e-04\n",
      "Epoch 29/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0140 - mse: 7.2471e-04 - val_loss: 0.0080 - val_mse: 3.6696e-04\n",
      "Epoch 30/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0157 - mse: 0.0011 - val_loss: 0.0040 - val_mse: 5.2260e-05\n",
      "Epoch 31/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0126 - mse: 6.3931e-04 - val_loss: 0.0057 - val_mse: 1.6080e-04\n",
      "Epoch 32/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0115 - mse: 4.9397e-04 - val_loss: 0.0059 - val_mse: 1.8313e-04\n",
      "Epoch 33/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0110 - mse: 4.6854e-04 - val_loss: 0.0034 - val_mse: 4.0795e-05\n",
      "Epoch 34/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0101 - mse: 3.9094e-04 - val_loss: 0.0040 - val_mse: 7.8384e-05\n",
      "Epoch 35/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0091 - mse: 3.3293e-04 - val_loss: 0.0050 - val_mse: 1.5195e-04\n",
      "Epoch 36/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0087 - mse: 3.1465e-04 - val_loss: 0.0038 - val_mse: 8.0435e-05\n",
      "Epoch 37/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0084 - mse: 3.0980e-04 - val_loss: 0.0031 - val_mse: 4.9257e-05\n",
      "Epoch 38/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0074 - mse: 2.1983e-04 - val_loss: 0.0048 - val_mse: 1.4141e-04\n",
      "Epoch 39/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0085 - mse: 3.5434e-04 - val_loss: 0.0032 - val_mse: 5.4717e-05\n",
      "Epoch 40/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0076 - mse: 2.3881e-04 - val_loss: 0.0022 - val_mse: 2.0893e-05\n",
      "Epoch 41/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0071 - mse: 2.2549e-04 - val_loss: 0.0035 - val_mse: 7.5509e-05\n",
      "Epoch 42/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0063 - mse: 1.5831e-04 - val_loss: 0.0027 - val_mse: 4.0713e-05\n",
      "Epoch 43/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0059 - mse: 1.6452e-04 - val_loss: 0.0030 - val_mse: 5.9927e-05\n",
      "Epoch 44/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0056 - mse: 1.4878e-04 - val_loss: 0.0028 - val_mse: 5.1287e-05\n",
      "Epoch 45/100\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0054 - mse: 1.2826e-04Restoring model weights from the end of the best epoch.\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0051 - mse: 1.1348e-04 - val_loss: 0.0027 - val_mse: 4.4981e-05\n",
      "Epoch 00045: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": "<tensorflow.python.keras.callbacks.History at 0x18710114820>"
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_s, y_train, epochs=100, validation_split=.1,\n",
    "              callbacks=[es],\n",
    "              verbose=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 995us/step - loss: 0.0469 - mse: 0.0084\n"
     ]
    },
    {
     "data": {
      "text/plain": "[0.046873196959495544, 0.008374566212296486]"
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test_s, y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# drkail6916.work@gmail.com /   "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [],
   "source": [
    "feature_list = ['radius',\n",
    "                'texture',\n",
    "                'perimeter',\n",
    "                'area',\n",
    "                'smoothness',\n",
    "                'compactness',\n",
    "                'concavity',\n",
    "                'concave points',\n",
    "                'symmetry',\n",
    "                'fractal dimension']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "data": {
      "text/plain": "['radius',\n 'texture',\n 'perimeter',\n 'area',\n 'smoothness',\n 'compactness',\n 'concavity',\n 'concave points',\n 'symmetry',\n 'fractal dimension',\n 'sex']"
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_list + ['sex']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}