{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "2_3_ANN_Fashion_MNIST.ipynb",
   "provenance": [],
   "collapsed_sections": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UdrP_vI3QcNd",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# ANN & Fashion MNIST\n",
    "\n",
    "<br> By Margaret Maynard-Reid, 4/24/2018\n",
    "\n",
    "![alt text](https://github.com/margaretmz/deep-learning/blob/master/images/modern%20dl_fash-mnist_keras.png?raw=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XLMRPLVCFwEc",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Why Fashion-MNIST?\n",
    "\n",
    "\n",
    "*   MNIST is too easy\n",
    "*   MNIST is overused\n",
    "*   MNIST can not represent modern Computer Vision tasks\n",
    "\n",
    "Read more about the Fashion-MINST dataset in this paper [here](https://arxiv.org/abs/1708.07747) (**Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning Algorithms**)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "d44TznbgZZgm",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the fashion-mnist pre-shuffled train data and test data\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.fashion_mnist.load_data()\n",
    "\n",
    "print(\"x_train shape:\", x_train.shape, \"y_train shape:\", y_train.shape)"
   ],
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28) y_train shape: (60000,)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tWORMSC8FDR4",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Visualize the data 반복실행 해보자"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "aFe4wHGRFKle",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "# Print training set shape - note there are 60,000 training data of image size of 28x28, 60,000 train labels)\n",
    "print(\"x_train shape:\", x_train.shape, \"y_train shape:\", y_train.shape)\n",
    "\n",
    "# Print the number of training and test datasets\n",
    "print(x_train.shape[0], 'train set')\n",
    "print(x_test.shape[0], 'test set')\n",
    "\n",
    "# Define the text labels\n",
    "fashion_mnist_labels = [\"T-shirt/top\",  # index 0\n",
    "                        \"Trouser\",  # index 1\n",
    "                        \"Pullover\",  # index 2\n",
    "                        \"Dress\",  # index 3\n",
    "                        \"Coat\",  # index 4\n",
    "                        \"Sandal\",  # index 5\n",
    "                        \"Shirt\",  # index 6\n",
    "                        \"Sneaker\",  # index 7\n",
    "                        \"Bag\",  # index 8\n",
    "                        \"Ankle boot\"]  # index 9\n",
    "\n",
    "# Image index, you can pick any number between 0 and 59,999\n",
    "img_index = np.random.randint(0, 59999)\n",
    "# y_train contains the lables, ranging from 0 to 9\n",
    "label_index = y_train[img_index]\n",
    "# Print the label, for example 2 Pullover\n",
    "print(\"y = \" + str(label_index) + \" \" + (fashion_mnist_labels[label_index]))\n",
    "# # Show one of the images from the training dataset\n",
    "plt.imshow(x_train[img_index])"
   ],
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28) y_train shape: (60000,)\n",
      "60000 train set\n",
      "10000 test set\n",
      "y = 8 Bag\n"
     ]
    },
    {
     "data": {
      "text/plain": "<matplotlib.image.AxesImage at 0x1d775274ca0>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "XqUyZdcCe6Ja",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "print(x_train.shape, x_test.shape, y_train.shape, y_test.shape)"
   ],
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28) (10000, 28, 28) (60000,) (10000,)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zx-Ee6LHZZgt",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "##  코딩 task!\n",
    "\n",
    "1. 전처리\n",
    "    * x : sc_____\n",
    "    * y : _______ encoding\n",
    "\n",
    "2. 모델링\n",
    "    * model에 모델 선언\n",
    "    * Input layer에 어떻게 전달할 것인지 고민 필요\n",
    "    * 쭈우우우욱 늘려주는 레이어를 사용할 것 (F______)\n",
    "    * 히든레이어는 최소 3개를 쓸 것!\n",
    "    * 노드 수는 512개를 기본으로 시작\n",
    "    * 자유롭게 바꿔가며 성능을 볼 것\n",
    "\n",
    "3. 학습\n",
    "    * epochs=50, validation_split=0.2\n",
    "    * early stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "x_train_s = x_train / 255\n",
    "x_test_s = x_test / 255\n",
    "\n",
    "y_train_o = keras.utils.to_categorical(y_train, 10)\n",
    "y_test_o = keras.utils.to_categorical(y_test, 10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "oRTnVHB7uiHz",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "#############\n",
    "# Your Code #\n",
    "#############\n",
    "keras.backend.clear_session()\n",
    "\n",
    "layers = [  ]\n",
    "il = keras.layers.Input(shape=(28, 28), name='Input')\n",
    "layers.append(il)\n",
    "layers.append(keras.layers.Flatten()(layers[-1]))\n",
    "for i in range(3):\n",
    "    layers.append(keras.layers.Dense(512, activation='relu', name=f'Hidden_{i + 1}')(layers[-1]))\n",
    "layers.append(keras.layers.Dense(10, activation='softmax', name='Output')(layers[-1]))\n",
    "\n",
    "model = keras.models.Model(layers[0], layers[-1])\n",
    "model_o = keras.models.Model(layers[0], layers[-1])\n",
    "\n",
    "model.compile(loss=keras.losses.sparse_categorical_crossentropy, optimizer='adam', metrics=['accuracy'])\n",
    "model_o.compile(loss=keras.losses.categorical_crossentropy, optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "es = keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                   min_delta=0,\n",
    "                                   patience=5,\n",
    "                                   verbose=1,\n",
    "                                   restore_best_weights=True)\n",
    "\n",
    "print(model.summary())\n",
    "print('-' * 100)\n",
    "print(model_o.summary())"
   ],
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Input (InputLayer)           [(None, 28, 28)]          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "Hidden_1 (Dense)             (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "Hidden_2 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "Hidden_3 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "Output (Dense)               (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 932,362\n",
      "Trainable params: 932,362\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Model: \"functional_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Input (InputLayer)           [(None, 28, 28)]          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "Hidden_1 (Dense)             (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "Hidden_2 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "Hidden_3 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "Output (Dense)               (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 932,362\n",
      "Trainable params: 932,362\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "   1/1500 [..............................] - ETA: 0s - loss: 2.3231 - accuracy: 0.1875WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0010s vs `on_train_batch_end` time: 0.0020s). Check your callbacks.\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.4919 - accuracy: 0.8200 - val_loss: 0.4087 - val_accuracy: 0.8494\n",
      "Epoch 2/50\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.3755 - accuracy: 0.8611 - val_loss: 0.3783 - val_accuracy: 0.8656\n",
      "Epoch 3/50\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.3330 - accuracy: 0.8771 - val_loss: 0.3696 - val_accuracy: 0.8695\n",
      "Epoch 4/50\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.3114 - accuracy: 0.8859 - val_loss: 0.3499 - val_accuracy: 0.8748\n",
      "Epoch 5/50\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.2933 - accuracy: 0.8909 - val_loss: 0.3383 - val_accuracy: 0.8778\n",
      "Epoch 6/50\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.2783 - accuracy: 0.8964 - val_loss: 0.3239 - val_accuracy: 0.8832\n",
      "Epoch 7/50\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.2648 - accuracy: 0.9009 - val_loss: 0.3288 - val_accuracy: 0.8836\n",
      "Epoch 8/50\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.2556 - accuracy: 0.9040 - val_loss: 0.3181 - val_accuracy: 0.8857\n",
      "Epoch 9/50\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.2397 - accuracy: 0.9090 - val_loss: 0.3179 - val_accuracy: 0.8884\n",
      "Epoch 10/50\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.2362 - accuracy: 0.9105 - val_loss: 0.3525 - val_accuracy: 0.8848\n",
      "Epoch 11/50\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.2255 - accuracy: 0.9133 - val_loss: 0.3495 - val_accuracy: 0.8843\n",
      "Epoch 12/50\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.2192 - accuracy: 0.9171 - val_loss: 0.3741 - val_accuracy: 0.8842\n",
      "Epoch 13/50\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.2113 - accuracy: 0.9196 - val_loss: 0.3541 - val_accuracy: 0.8905\n",
      "Epoch 14/50\n",
      "1487/1500 [============================>.] - ETA: 0s - loss: 0.2053 - accuracy: 0.9203Restoring model weights from the end of the best epoch.\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.2048 - accuracy: 0.9205 - val_loss: 0.3546 - val_accuracy: 0.8946\n",
      "Epoch 00014: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": "<tensorflow.python.keras.callbacks.History at 0x1d735d24d00>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_o.fit(x_train_s, y_train_o, verbose=1, epochs=50,\n",
    "          callbacks=[es],\n",
    "          validation_split=.2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "pred_o = model_o.predict(x_test_s)\n",
    "pred_to = model_o.predict(x_train_s)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습 정확도:  91.15%\n",
      "테스트 정확도:  87.95%\n",
      "313/313 [==============================] - 0s 932us/step - loss: 0.3423 - accuracy: 0.8795\n",
      "[0.342330664396286, 0.8794999718666077]\n"
     ]
    }
   ],
   "source": [
    "print(f'학습 정확도: {accuracy_score(y_train, pred_to.argmax(axis=1)) * 100: .2f}%')\n",
    "print(f'테스트 정확도: {accuracy_score(y_test, pred_o.argmax(axis=1))*100: .2f}%')\n",
    "\n",
    "print(f'{model_o.evaluate(x_test_s, y_test_o)}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "uVSPMrDEe4im",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "#############\n",
    "# Your Code #\n",
    "#############\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "gQ1GIsfafE07",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "#############\n",
    "# Your Code #\n",
    "#############\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "ytuvtzg1urGb",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "#############\n",
    "# Your Code #\n",
    "#############\n",
    "\n",
    "\n",
    "#### 모델 요약\n",
    "model.summary()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "SbCR_wsLvx0c",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "#############\n",
    "# Your Code #\n",
    "#############\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oJv7XEk10bOv",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Visualize prediction\n",
    "\n",
    "위에서 지키라고 한 사항들 안지키면 동작을 안할껄...?"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "L_B3UemLh6ON",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "score = model_o.evaluate(x_test_s, y_test_o, verbose=0)\n",
    "\n",
    "# Print test accuracy\n",
    "print('\\n', 'Test accuracy:', score[1])\n",
    "y_hat = model_o.predict(x_test_s).argmax(axis=1)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "QwNmlfIC0YxM",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "####### 반복실행해보자\n",
    "\n",
    "# Plot a random sample of 10 test images, their predicted labels and ground truth\n",
    "figure = plt.figure(figsize=(20, 8))\n",
    "for i, index in enumerate(np.random.choice(x_test_s.shape[0], size=15, replace=False)):\n",
    "    ax = figure.add_subplot(3, 5, i + 1, xticks=[], yticks=[])\n",
    "    # Display each image\n",
    "    ax.imshow(np.squeeze(x_test_s[index].reshape([28, -1])))\n",
    "    predict_index = y_hat[index]\n",
    "    true_index = y_test_o[index].argmax(axis=0)\n",
    "    # Set the title for each image\n",
    "    ax.set_title(\"{} ({})\".format(fashion_mnist_labels[predict_index],\n",
    "                                  fashion_mnist_labels[true_index]),\n",
    "                 color=(\"green\" if predict_index == true_index else \"red\"))"
   ],
   "execution_count": null,
   "outputs": []
  }
 ]
}